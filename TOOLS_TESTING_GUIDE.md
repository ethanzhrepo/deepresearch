# DeepResearch å·¥å…·æµ‹è¯•æŒ‡å—

è¿™ä¸ªæ–‡æ¡£æä¾›äº†æ‰€æœ‰å·¥å…·å’Œ Browser-Use åŠŸèƒ½çš„è¯¦ç»†æµ‹è¯•å‘½ä»¤å’Œé…ç½®ç¤ºä¾‹ã€‚

## ðŸ“‹ ç›®å½•

1. [å¿«é€ŸéªŒè¯æ‰€æœ‰å·¥å…·](#å¿«é€ŸéªŒè¯æ‰€æœ‰å·¥å…·)
2. [æœç´¢å¼•æ“Žæµ‹è¯•](#æœç´¢å¼•æ“Žæµ‹è¯•)
3. [Browser-Use å·¥å…·æµ‹è¯•](#browser-use-å·¥å…·æµ‹è¯•)
4. [å…¶ä»–å·¥å…·æµ‹è¯•](#å…¶ä»–å·¥å…·æµ‹è¯•)
5. [å®Œæ•´ç ”ç©¶æµç¨‹æµ‹è¯•](#å®Œæ•´ç ”ç©¶æµç¨‹æµ‹è¯•)
6. [æ•…éšœæŽ’é™¤](#æ•…éšœæŽ’é™¤)

---

## ðŸš€ å¿«é€ŸéªŒè¯æ‰€æœ‰å·¥å…·

### 1. æ£€æŸ¥é…ç½®å’Œ API å¯†é’¥
```bash
# æ£€æŸ¥ç³»ç»Ÿé…ç½®
python main.py config-check

# é¢„æœŸè¾“å‡ºï¼šæ˜¾ç¤ºæ‰€æœ‰ API å¯†é’¥çŠ¶æ€å’Œå·¥å…·é…ç½®
```

### 2. éªŒè¯æ‰€æœ‰å·¥å…·æ³¨å†Œ
```bash
# æµ‹è¯•å·¥å…·æ³¨å†Œ
python -c "
from tools.tool_registry import ToolRegistry
registry = ToolRegistry()
print('å·²æ³¨å†Œçš„å·¥å…·:')
for name, tool in registry.tools.items():
    print(f'  - {name}: {tool.__class__.__name__}')
print(f'\\næ€»è®¡: {len(registry.tools)} ä¸ªå·¥å…·')
"
```

### 3. å¿«é€Ÿæœç´¢å¼•æ“Žæµ‹è¯•
```bash
# æµ‹è¯•æœç´¢å¼•æ“Žç®¡ç†å™¨
python -c "
from tools.search_engines import SearchEngineManager
manager = SearchEngineManager()
print('å¯ç”¨æœç´¢å¼•æ“Ž:', list(manager.engines.keys()))
results = manager.search('äººå·¥æ™ºèƒ½', max_results=2)
print(f'æœç´¢ç»“æžœ: {len(results)} æ¡')
for i, result in enumerate(results[:2], 1):
    print(f'{i}. {result.title[:50]}... (æ¥æº: {result.source})')
"
```

---

## ðŸ” æœç´¢å¼•æ“Žæµ‹è¯•

### Tavily Search (AI ä¼˜åŒ–æœç´¢)
```bash
# åŸºç¡€ Tavily æœç´¢æµ‹è¯•
python -c "
from tools.search_engines import TavilySearch
import os

config = {
    'api_key': os.getenv('TAVILY_API_KEY'),
    'timeout': 30,
    'max_results': 5,
    'include_answer': True,
    'include_raw_content': False
}

if config['api_key']:
    tavily = TavilySearch(config)
    print('ðŸ” æµ‹è¯• Tavily æœç´¢...')
    results = tavily.search('æœºå™¨å­¦ä¹ æœ€æ–°è¿›å±•', max_results=3)
    print(f'æ‰¾åˆ° {len(results)} ä¸ªç»“æžœ:')
    for i, result in enumerate(results, 1):
        print(f'{i}. {result.title}')
        print(f'   æ¥æº: {result.source}')
        print(f'   URL: {result.url}')
        print(f'   æ‘˜è¦: {result.snippet[:100]}...')
        print()
else:
    print('âŒ TAVILY_API_KEY æœªé…ç½®')
"
```

### DuckDuckGo Search (å…è´¹æœç´¢)
```bash
# DuckDuckGo æœç´¢æµ‹è¯•
python -c "
from tools.search_engines import DuckDuckGoSearch

config = {
    'timeout': 30,
    'max_results': 5,
    'region': 'cn-zh',
    'safe_search': 'moderate'
}

try:
    ddg = DuckDuckGoSearch(config)
    print('ðŸ” æµ‹è¯• DuckDuckGo æœç´¢...')
    results = ddg.search('Python ç¼–ç¨‹æ•™ç¨‹', max_results=3)
    print(f'æ‰¾åˆ° {len(results)} ä¸ªç»“æžœ:')
    for i, result in enumerate(results, 1):
        print(f'{i}. {result.title[:60]}...')
        print(f'   URL: {result.url}')
        print()
except Exception as e:
    print(f'âŒ DuckDuckGo æœç´¢å¤±è´¥: {e}')
"
```

### ArXiv å­¦æœ¯æœç´¢
```bash
# ArXiv å­¦æœ¯è®ºæ–‡æœç´¢æµ‹è¯•
python -c "
from tools.search_engines import ArxivSearch

config = {
    'timeout': 30,
    'max_results': 5,
    'sort_by': 'relevance',
    'sort_order': 'descending'
}

try:
    arxiv = ArxivSearch(config)
    print('ðŸ” æµ‹è¯• ArXiv å­¦æœ¯æœç´¢...')
    results = arxiv.search('machine learning', max_results=3)
    print(f'æ‰¾åˆ° {len(results)} ä¸ªå­¦æœ¯è®ºæ–‡:')
    for i, result in enumerate(results, 1):
        print(f'{i}. {result.title}')
        print(f'   ArXiv ID: {result.metadata.get(\"arxiv_id\", \"N/A\")}')
        print(f'   ä½œè€…: {result.metadata.get(\"authors\", [])}')
        print(f'   åˆ†ç±»: {result.metadata.get(\"categories\", [])}')
        print(f'   å‘å¸ƒæ—¶é—´: {result.metadata.get(\"published\", \"N/A\")}')
        print()
except Exception as e:
    print(f'âŒ ArXiv æœç´¢å¤±è´¥: {e}')
"
```

### å¤šå¼•æ“Žå¯¹æ¯”æœç´¢
```bash
# å¯¹æ¯”å¤šä¸ªæœç´¢å¼•æ“Žçš„ç»“æžœ
python -c "
from tools.search_engines import SearchEngineManager

manager = SearchEngineManager()
query = 'åŒºå—é“¾æŠ€æœ¯åº”ç”¨'

print(f'ðŸ” æœç´¢æŸ¥è¯¢: {query}')
print('=' * 50)

results = manager.search_multiple_engines(
    query=query,
    engines=['tavily', 'duckduckgo', 'arxiv'],
    max_results_per_engine=2
)

for engine, engine_results in results.items():
    print(f'\nðŸ“Š {engine.upper()} æœç´¢ç»“æžœ ({len(engine_results)} æ¡):')
    for i, result in enumerate(engine_results, 1):
        print(f'  {i}. {result.title[:60]}...')
        print(f'     æ¥æº: {result.source}')
"
```

---

## ðŸŒ Browser-Use å·¥å…·æµ‹è¯•

### åŸºç¡€ Browser-Use åŠŸèƒ½æµ‹è¯•
```bash
# æµ‹è¯• Browser-Use å·¥å…·åˆå§‹åŒ–
python -c "
from tools.browser_use_tool import BrowserUseTool
from config import config

print('ðŸŒ æµ‹è¯• Browser-Use å·¥å…·åˆå§‹åŒ–...')

try:
    browser_tool = BrowserUseTool()
    print('âœ… Browser-Use å·¥å…·åˆå§‹åŒ–æˆåŠŸ')
    print(f'LLM æä¾›å•†: {browser_tool.llm_provider}')
    print(f'LLM æ¨¡åž‹: {browser_tool.llm_model}')
    print(f'æµè§ˆå™¨é…ç½®: {browser_tool.browser_config}')
    print(f'å¯ç”¨åŠŸèƒ½: {list(browser_tool.features.keys())}')
except Exception as e:
    print(f'âŒ Browser-Use å·¥å…·åˆå§‹åŒ–å¤±è´¥: {e}')
"
```

### Browser-Use æœç´¢å’Œæå–æµ‹è¯•
```bash
# åˆ›å»º Browser-Use æœç´¢æµ‹è¯•è„šæœ¬
cat > test_browser_use_search.py << 'EOF'
#!/usr/bin/env python3
"""Browser-Use æœç´¢å’Œæå–åŠŸèƒ½æµ‹è¯•"""

import asyncio
import sys
import os
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from tools.browser_use_tool import BrowserUseTool

async def test_browser_search():
    """æµ‹è¯•æµè§ˆå™¨æœç´¢å’Œæ•°æ®æå–"""
    try:
        browser_tool = BrowserUseTool()
        
        # æµ‹è¯•æœç´¢å’Œæå–åŠŸèƒ½
        print("ðŸ” æµ‹è¯•æµè§ˆå™¨æœç´¢å’Œæå–...")
        
        task_config = {
            "search_query": "Python æœ€æ–°ç‰ˆæœ¬ç‰¹æ€§",
            "target_websites": ["python.org", "docs.python.org"],
            "extract_elements": ["h1", "h2", "p"],
            "max_pages": 2,
            "timeout": 60
        }
        
        # ä½¿ç”¨ search_and_extract åŠŸèƒ½
        result = await browser_tool.search_and_extract(task_config)
        
        if result["success"]:
            print("âœ… æœç´¢å’Œæå–æˆåŠŸ")
            print(f"ðŸ“Š æå–çš„æ•°æ®æ¡ç›®: {len(result.get('extracted_data', []))}")
            print(f"ðŸŒ è®¿é—®çš„é¡µé¢: {len(result.get('visited_pages', []))}")
            
            # æ˜¾ç¤ºéƒ¨åˆ†æå–çš„æ•°æ®
            for i, data in enumerate(result.get('extracted_data', [])[:3], 1):
                print(f"\nðŸ“„ æ•°æ®æ¡ç›® {i}:")
                print(f"   æ ‡é¢˜: {data.get('title', 'N/A')[:50]}...")
                print(f"   URL: {data.get('url', 'N/A')}")
                print(f"   å†…å®¹: {data.get('content', 'N/A')[:100]}...")
        else:
            print(f"âŒ æœç´¢å’Œæå–å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            
    except Exception as e:
        print(f"ðŸ’¥ æµ‹è¯•å‡ºé”™: {e}")

if __name__ == "__main__":
    asyncio.run(test_browser_search())
EOF

# è¿è¡Œ Browser-Use æœç´¢æµ‹è¯•
python test_browser_use_search.py
```

### Browser-Use è¡¨å•å¡«å†™æµ‹è¯•
```bash
# åˆ›å»ºè¡¨å•å¡«å†™æµ‹è¯•è„šæœ¬
cat > test_browser_form.py << 'EOF'
#!/usr/bin/env python3
"""Browser-Use è¡¨å•å¡«å†™åŠŸèƒ½æµ‹è¯•"""

import asyncio
import sys
import os
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from tools.browser_use_tool import BrowserUseTool

async def test_browser_form():
    """æµ‹è¯•æµè§ˆå™¨è¡¨å•å¡«å†™åŠŸèƒ½"""
    try:
        browser_tool = BrowserUseTool()
        
        print("ðŸ“ æµ‹è¯•æµè§ˆå™¨è¡¨å•å¡«å†™...")
        
        # è¡¨å•å¡«å†™é…ç½®ï¼ˆä»¥ Google æœç´¢ä¸ºä¾‹ï¼‰
        form_config = {
            "url": "https://www.google.com",
            "form_data": {
                "q": "äººå·¥æ™ºèƒ½ç ”ç©¶è¿›å±•"  # Google æœç´¢æ¡†
            },
            "submit_button_selector": "input[type='submit']",
            "wait_for_results": True,
            "extract_results": True
        }
        
        result = await browser_tool.fill_form(form_config)
        
        if result["success"]:
            print("âœ… è¡¨å•å¡«å†™æˆåŠŸ")
            print(f"ðŸŒ æœ€ç»ˆé¡µé¢ URL: {result.get('final_url', 'N/A')}")
            print(f"ðŸ“Š æå–çš„ç»“æžœæ•°é‡: {len(result.get('form_results', []))}")
        else:
            print(f"âŒ è¡¨å•å¡«å†™å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            
    except Exception as e:
        print(f"ðŸ’¥ æµ‹è¯•å‡ºé”™: {e}")

if __name__ == "__main__":
    asyncio.run(test_browser_form())
EOF

# è¿è¡Œè¡¨å•å¡«å†™æµ‹è¯•
python test_browser_form.py
```

### Browser-Use è‡ªå®šä¹‰ä»»åŠ¡æµ‹è¯•
```bash
# åˆ›å»ºè‡ªå®šä¹‰ä»»åŠ¡æµ‹è¯•è„šæœ¬
cat > test_browser_custom.py << 'EOF'
#!/usr/bin/env python3
"""Browser-Use è‡ªå®šä¹‰ä»»åŠ¡åŠŸèƒ½æµ‹è¯•"""

import asyncio
import sys
import os
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from tools.browser_use_tool import BrowserUseTool

async def test_custom_task():
    """æµ‹è¯•è‡ªå®šä¹‰æµè§ˆå™¨ä»»åŠ¡"""
    try:
        browser_tool = BrowserUseTool()
        
        print("ðŸŽ¯ æµ‹è¯•è‡ªå®šä¹‰æµè§ˆå™¨ä»»åŠ¡...")
        
        # è‡ªå®šä¹‰ä»»åŠ¡ï¼šè®¿é—® GitHub å¹¶æå– Python é¡¹ç›®ä¿¡æ¯
        custom_task = {
            "task_description": "è®¿é—® GitHub æœç´¢ Python æœºå™¨å­¦ä¹ é¡¹ç›®ï¼Œæå–å‰3ä¸ªé¡¹ç›®çš„åç§°ã€æè¿°å’Œæ˜Ÿæ•°",
            "steps": [
                {"action": "navigate", "url": "https://github.com"},
                {"action": "search", "query": "python machine learning", "search_type": "repositories"},
                {"action": "extract", "selector": ".repo-list-item", "limit": 3},
                {"action": "get_details", "fields": ["name", "description", "stars"]}
            ],
            "timeout": 120,
            "save_screenshots": True
        }
        
        result = await browser_tool.execute_custom_task(custom_task)
        
        if result["success"]:
            print("âœ… è‡ªå®šä¹‰ä»»åŠ¡æ‰§è¡ŒæˆåŠŸ")
            print(f"ðŸ“Š æ‰§è¡Œçš„æ­¥éª¤æ•°: {len(result.get('executed_steps', []))}")
            print(f"ðŸ–¼ï¸ æˆªå›¾ä¿å­˜ä½ç½®: {result.get('screenshots_path', 'N/A')}")
            
            # æ˜¾ç¤ºæå–çš„é¡¹ç›®ä¿¡æ¯
            extracted_data = result.get('extracted_data', [])
            print(f"\nðŸ æ‰¾åˆ° {len(extracted_data)} ä¸ª Python é¡¹ç›®:")
            for i, project in enumerate(extracted_data[:3], 1):
                print(f"  {i}. {project.get('name', 'N/A')}")
                print(f"     æè¿°: {project.get('description', 'N/A')[:80]}...")
                print(f"     â­ Stars: {project.get('stars', 'N/A')}")
        else:
            print(f"âŒ è‡ªå®šä¹‰ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            
    except Exception as e:
        print(f"ðŸ’¥ æµ‹è¯•å‡ºé”™: {e}")

if __name__ == "__main__":
    asyncio.run(test_custom_task())
EOF

# è¿è¡Œè‡ªå®šä¹‰ä»»åŠ¡æµ‹è¯•
python test_browser_custom.py
```

---

## ðŸ”§ å…¶ä»–å·¥å…·æµ‹è¯•

### ä»£ç æ‰§è¡Œå·¥å…·æµ‹è¯•
```bash
# æµ‹è¯•ä»£ç æ‰§è¡Œå·¥å…·
python -c "
from tools.tool_registry import CodeTool

code_tool = CodeTool()
print('ðŸ’» æµ‹è¯•ä»£ç æ‰§è¡Œå·¥å…·...')

# æµ‹è¯• Python ä»£ç æ‰§è¡Œ
python_code = '''
import pandas as pd
import numpy as np

# åˆ›å»ºç¤ºä¾‹æ•°æ®
data = {
    'name': ['Alice', 'Bob', 'Charlie'],
    'age': [25, 30, 35],
    'score': [95, 87, 92]
}

df = pd.DataFrame(data)
print("æ•°æ®æ¡†ä¿¡æ¯:")
print(df.info())
print("\næ•°æ®é¢„è§ˆ:")
print(df.head())
print(f"\nå¹³å‡åˆ†æ•°: {df['score'].mean():.2f}")
'''

try:
    result = code_tool._run(python_code)
    print('âœ… ä»£ç æ‰§è¡ŒæˆåŠŸ:')
    print(result)
except Exception as e:
    print(f'âŒ ä»£ç æ‰§è¡Œå¤±è´¥: {e}')
"
```

### æ–‡ä»¶å¤„ç†å·¥å…·æµ‹è¯•
```bash
# æµ‹è¯•æ–‡ä»¶å¤„ç†å·¥å…·
python -c "
from tools.tool_registry import FileTool
import tempfile
import os

file_tool = FileTool()
print('ðŸ“ æµ‹è¯•æ–‡ä»¶å¤„ç†å·¥å…·...')

# åˆ›å»ºä¸´æ—¶æ–‡ä»¶
with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
    f.write('è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡ä»¶\nåŒ…å«å¤šè¡Œæ–‡æœ¬\nç”¨äºŽæµ‹è¯•æ–‡ä»¶è¯»å–åŠŸèƒ½')
    temp_file = f.name

try:
    # æµ‹è¯•æ–‡ä»¶è¯»å–
    result = file_tool._run(f'read:{temp_file}')
    print('âœ… æ–‡ä»¶è¯»å–æˆåŠŸ:')
    print(result[:200] + '...' if len(result) > 200 else result)
finally:
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    os.unlink(temp_file)
"
```

---

## ðŸ§ª å®Œæ•´ç ”ç©¶æµç¨‹æµ‹è¯•

### ç®€å•ç ”ç©¶æµç¨‹æµ‹è¯•
```bash
# å¿«é€Ÿç ”ç©¶æµç¨‹æµ‹è¯•ï¼ˆéžäº¤äº’æ¨¡å¼ï¼‰
python main.py research "äººå·¥æ™ºèƒ½åœ¨æ•™è‚²é¢†åŸŸçš„åº”ç”¨" \
    --provider deepseek \
    --max-sections 2 \
    --language zh-CN \
    --output-dir output \
    --no-interactive
```

### å®Œæ•´ç ”ç©¶æµç¨‹æµ‹è¯•
```bash
# å®Œæ•´ç ”ç©¶æµç¨‹æµ‹è¯•ï¼ˆäº¤äº’æ¨¡å¼ï¼‰
python main.py research "åŒºå—é“¾æŠ€æœ¯çš„å‘å±•è¶‹åŠ¿" \
    --provider deepseek \
    --max-sections 4 \
    --language zh-CN \
    --enable-browser-use
```

### ä½¿ç”¨ç‰¹å®šæœç´¢å¼•æ“Žçš„ç ”ç©¶
```bash
# ä½¿ç”¨ Tavily æœç´¢å¼•æ“Žè¿›è¡Œç ”ç©¶
python -c "
import asyncio
from workflow.graph import ResearchWorkflow
from tools.search_engines import SearchEngineManager

async def test_research_with_tavily():
    workflow = ResearchWorkflow(
        llm_provider='deepseek',
        max_sections=2,
        interactive_mode=False
    )
    
    # å¼ºåˆ¶ä½¿ç”¨ Tavily æœç´¢
    original_search = workflow.search_manager.search
    def force_tavily_search(query, **kwargs):
        return workflow.search_manager.search(query, engine='tavily', **kwargs)
    workflow.search_manager.search = force_tavily_search
    
    print('ðŸ” ä½¿ç”¨ Tavily æœç´¢å¼•æ“Žè¿›è¡Œç ”ç©¶...')
    outline, content_map = await workflow.run_full_workflow('é‡å­è®¡ç®—åŸºç¡€åŽŸç†')
    
    if outline and content_map:
        print(f'âœ… ç ”ç©¶å®Œæˆï¼Œç”Ÿæˆ {len(content_map)} ä¸ªå†…å®¹éƒ¨åˆ†')
        
        # æ£€æŸ¥å¼•ç”¨æ¥æº
        sources_count = sum(1 for content in content_map.values() if content.sources)
        print(f'ðŸ“š åŒ…å«å¼•ç”¨æ¥æºçš„éƒ¨åˆ†: {sources_count}/{len(content_map)}')
    else:
        print('âŒ ç ”ç©¶å¤±è´¥')

asyncio.run(test_research_with_tavily())
"
```

---

## ðŸš¨ æ•…éšœæŽ’é™¤

### å¸¸è§é—®é¢˜è¯Šæ–­
```bash
# åˆ›å»ºè¯Šæ–­è„šæœ¬
cat > diagnose_tools.py << 'EOF'
#!/usr/bin/env python3
"""å·¥å…·è¯Šæ–­è„šæœ¬"""

import os
import sys
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

def diagnose_environment():
    """è¯Šæ–­çŽ¯å¢ƒé…ç½®"""
    print("ðŸ” è¯Šæ–­ç³»ç»ŸçŽ¯å¢ƒ...")
    
    # æ£€æŸ¥ Python ç‰ˆæœ¬
    print(f"Python ç‰ˆæœ¬: {sys.version}")
    
    # æ£€æŸ¥å…³é”®ä¾èµ–åŒ…
    required_packages = [
        'requests', 'pydantic', 'langchain', 'langgraph', 
        'duckduckgo_search', 'feedparser', 'browser_use'
    ]
    
    missing_packages = []
    for package in required_packages:
        try:
            __import__(package)
            print(f"âœ… {package}: å·²å®‰è£…")
        except ImportError:
            print(f"âŒ {package}: æœªå®‰è£…")
            missing_packages.append(package)
    
    if missing_packages:
        print(f"\nðŸ“¦ éœ€è¦å®‰è£…çš„åŒ…: {', '.join(missing_packages)}")
        print(f"å®‰è£…å‘½ä»¤: pip install {' '.join(missing_packages)}")
    
    return len(missing_packages) == 0

def diagnose_api_keys():
    """è¯Šæ–­ API å¯†é’¥é…ç½®"""
    print("\nðŸ”‘ è¯Šæ–­ API å¯†é’¥...")
    
    api_keys = {
        'TAVILY_API_KEY': 'Tavily æœç´¢',
        'BRAVE_SEARCH_API_KEY': 'Brave æœç´¢',
        'SERPAPI_KEY': 'Google æœç´¢',
        'BING_SEARCH_KEY': 'Bing æœç´¢',
        'OPENAI_API_KEY': 'OpenAI',
        'ANTHROPIC_API_KEY': 'Claude',
        'GOOGLE_API_KEY': 'Gemini',
        'DEEPSEEK_API_KEY': 'DeepSeek'
    }
    
    configured_keys = 0
    for key, name in api_keys.items():
        if os.getenv(key):
            print(f"âœ… {name}: å·²é…ç½®")
            configured_keys += 1
        else:
            print(f"âŒ {name}: æœªé…ç½®")
    
    print(f"\nðŸ“Š å·²é…ç½® {configured_keys}/{len(api_keys)} ä¸ª API å¯†é’¥")
    return configured_keys > 0

def diagnose_search_engines():
    """è¯Šæ–­æœç´¢å¼•æ“Ž"""
    print("\nðŸ” è¯Šæ–­æœç´¢å¼•æ“Ž...")
    
    try:
        from tools.search_engines import SearchEngineManager
        manager = SearchEngineManager()
        
        available_engines = manager.get_available_engines()
        print(f"å¯ç”¨æœç´¢å¼•æ“Ž: {', '.join(available_engines)}")
        
        if available_engines:
            # æµ‹è¯•ç¬¬ä¸€ä¸ªå¯ç”¨çš„æœç´¢å¼•æ“Ž
            test_engine = available_engines[0]
            print(f"æµ‹è¯• {test_engine} æœç´¢...")
            results = manager.search("test", engine=test_engine, max_results=1)
            if results:
                print(f"âœ… {test_engine} æœç´¢æ­£å¸¸")
                return True
            else:
                print(f"âŒ {test_engine} æœç´¢æ— ç»“æžœ")
                return False
        else:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„æœç´¢å¼•æ“Ž")
            return False
            
    except Exception as e:
        print(f"âŒ æœç´¢å¼•æ“Žè¯Šæ–­å¤±è´¥: {e}")
        return False

def diagnose_browser_use():
    """è¯Šæ–­ Browser-Use å·¥å…·"""
    print("\nðŸŒ è¯Šæ–­ Browser-Use å·¥å…·...")
    
    try:
        from tools.browser_use_tool import BrowserUseTool
        browser_tool = BrowserUseTool()
        print("âœ… Browser-Use å·¥å…·åˆå§‹åŒ–æˆåŠŸ")
        return True
    except Exception as e:
        print(f"âŒ Browser-Use å·¥å…·åˆå§‹åŒ–å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    print("ðŸ¥ DeepResearch å·¥å…·è¯Šæ–­")
    print("=" * 50)
    
    checks = [
        diagnose_environment(),
        diagnose_api_keys(),
        diagnose_search_engines(),
        diagnose_browser_use()
    ]
    
    passed = sum(checks)
    total = len(checks)
    
    print(f"\nðŸ“Š è¯Šæ–­ç»“æžœ: {passed}/{total} é¡¹æ£€æŸ¥é€šè¿‡")
    
    if passed == total:
        print("ðŸŽ‰ æ‰€æœ‰å·¥å…·æ­£å¸¸ï¼Œå¯ä»¥å¼€å§‹ä½¿ç”¨ï¼")
    else:
        print("âš ï¸ éƒ¨åˆ†å·¥å…·å­˜åœ¨é—®é¢˜ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ä¿¡æ¯")
EOF

# è¿è¡Œè¯Šæ–­
python diagnose_tools.py
```

### è°ƒè¯•æ¨¡å¼æµ‹è¯•
```bash
# å¯ç”¨è¯¦ç»†æ—¥å¿—è¿›è¡Œè°ƒè¯•
export DEBUG=1
python main.py research "æµ‹è¯•ä¸»é¢˜" --provider deepseek --debug
```

### ä¿®å¤å¼•ç”¨æ¥æºé—®é¢˜æµ‹è¯•
```bash
# è¿è¡Œå¼•ç”¨æ¥æºä¿®å¤æµ‹è¯•
python test_sources_fix.py
```

---

## ðŸ“ æµ‹è¯•æ£€æŸ¥æ¸…å•

ä½¿ç”¨æ­¤æ£€æŸ¥æ¸…å•ç¡®ä¿æ‰€æœ‰åŠŸèƒ½æ­£å¸¸ï¼š

- [ ] **çŽ¯å¢ƒé…ç½®**: Python ä¾èµ–åŒ…å·²å®‰è£…
- [ ] **API å¯†é’¥**: è‡³å°‘é…ç½®ä¸€ä¸ª LLM å’Œä¸€ä¸ªæœç´¢å¼•æ“Žçš„ API å¯†é’¥
- [ ] **æœç´¢å¼•æ“Ž**: 
  - [ ] Tavily æœç´¢æ­£å¸¸
  - [ ] DuckDuckGo æœç´¢æ­£å¸¸
  - [ ] ArXiv æœç´¢æ­£å¸¸
- [ ] **Browser-Use å·¥å…·**:
  - [ ] å·¥å…·åˆå§‹åŒ–æˆåŠŸ
  - [ ] æœç´¢å’Œæå–åŠŸèƒ½æ­£å¸¸
  - [ ] è¡¨å•å¡«å†™åŠŸèƒ½æ­£å¸¸
  - [ ] è‡ªå®šä¹‰ä»»åŠ¡æ‰§è¡Œæ­£å¸¸
- [ ] **å…¶ä»–å·¥å…·**:
  - [ ] ä»£ç æ‰§è¡Œå·¥å…·æ­£å¸¸
  - [ ] æ–‡ä»¶å¤„ç†å·¥å…·æ­£å¸¸
- [ ] **å®Œæ•´æµç¨‹**:
  - [ ] ç ”ç©¶æçº²ç”Ÿæˆæ­£å¸¸
  - [ ] å†…å®¹ç”ŸæˆåŒ…å«å¼•ç”¨æ¥æº
  - [ ] æœ€ç»ˆæŠ¥å‘Šå¯¼å‡ºæˆåŠŸ
- [ ] **å¼•ç”¨æ¥æº**: æŠ¥å‘Šä¸­æ­£ç¡®æ˜¾ç¤ºå‚è€ƒèµ„æ–™

---

## ðŸŽ¯ æ€§èƒ½åŸºå‡†æµ‹è¯•

```bash
# åˆ›å»ºæ€§èƒ½æµ‹è¯•è„šæœ¬
cat > benchmark_tools.py << 'EOF'
#!/usr/bin/env python3
"""å·¥å…·æ€§èƒ½åŸºå‡†æµ‹è¯•"""

import asyncio
import time
import sys
import os
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from tools.search_engines import SearchEngineManager
from workflow.graph import ResearchWorkflow

async def benchmark_search_engines():
    """æœç´¢å¼•æ“Žæ€§èƒ½åŸºå‡†æµ‹è¯•"""
    print("â±ï¸ æœç´¢å¼•æ“Žæ€§èƒ½æµ‹è¯•...")
    
    manager = SearchEngineManager()
    queries = ["äººå·¥æ™ºèƒ½", "åŒºå—é“¾æŠ€æœ¯", "é‡å­è®¡ç®—"]
    
    for engine in manager.get_available_engines():
        print(f"\nðŸ” æµ‹è¯• {engine}:")
        total_time = 0
        total_results = 0
        
        for query in queries:
            start_time = time.time()
            results = manager.search(query, engine=engine, max_results=5)
            end_time = time.time()
            
            query_time = end_time - start_time
            total_time += query_time
            total_results += len(results)
            
            print(f"  æŸ¥è¯¢ '{query}': {len(results)} ç»“æžœ, {query_time:.2f}s")
        
        avg_time = total_time / len(queries)
        avg_results = total_results / len(queries)
        print(f"  å¹³å‡: {avg_results:.1f} ç»“æžœ/æŸ¥è¯¢, {avg_time:.2f}s/æŸ¥è¯¢")

async def benchmark_research_workflow():
    """ç ”ç©¶æµç¨‹æ€§èƒ½åŸºå‡†æµ‹è¯•"""
    print("\nâ±ï¸ ç ”ç©¶æµç¨‹æ€§èƒ½æµ‹è¯•...")
    
    workflow = ResearchWorkflow(
        llm_provider="deepseek",
        max_sections=2,
        interactive_mode=False
    )
    
    test_topics = ["æœºå™¨å­¦ä¹ åŸºç¡€", "ç½‘ç»œå®‰å…¨æ¦‚è¿°"]
    
    for topic in test_topics:
        print(f"\nðŸ“ æµ‹è¯•ä¸»é¢˜: {topic}")
        
        start_time = time.time()
        outline, content_map = await workflow.run_full_workflow(topic)
        end_time = time.time()
        
        total_time = end_time - start_time
        
        if outline and content_map:
            print(f"  âœ… å®Œæˆæ—¶é—´: {total_time:.2f}s")
            print(f"  ðŸ“Š ç”Ÿæˆç« èŠ‚: {len(outline.sections)}")
            print(f"  ðŸ“ å†…å®¹éƒ¨åˆ†: {len(content_map)}")
            
            # ç»Ÿè®¡å¼•ç”¨æ¥æº
            sources_count = sum(len(content.sources) for content in content_map.values())
            print(f"  ðŸ“š å¼•ç”¨æ¥æº: {sources_count} ä¸ª")
        else:
            print(f"  âŒ å¤±è´¥ï¼Œè€—æ—¶: {total_time:.2f}s")

if __name__ == "__main__":
    asyncio.run(benchmark_search_engines())
    asyncio.run(benchmark_research_workflow())
EOF

# è¿è¡Œæ€§èƒ½æµ‹è¯•
python benchmark_tools.py
```

---

## ðŸ“ž èŽ·å–å¸®åŠ©

å¦‚æžœé‡åˆ°é—®é¢˜ï¼Œè¯·ï¼š

1. **æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶**: `deepresearch.log`
2. **è¿è¡Œè¯Šæ–­è„šæœ¬**: `python diagnose_tools.py`
3. **æ£€æŸ¥é…ç½®æ–‡ä»¶**: `config.yml` å’Œ `.env`
4. **éªŒè¯ API å¯†é’¥**: `python main.py config-check`
5. **æŸ¥çœ‹è¯¦ç»†é”™è¯¯**: ä½¿ç”¨ `--debug` å‚æ•°

---

## ðŸŽ‰ æ­å–œï¼

å¦‚æžœæ‰€æœ‰æµ‹è¯•éƒ½é€šè¿‡ï¼Œæ‚¨çš„ DeepResearch ç³»ç»Ÿå·²ç»å®Œå…¨é…ç½®å¥½ï¼Œå¯ä»¥å¼€å§‹è¿›è¡Œé«˜è´¨é‡çš„è‡ªåŠ¨åŒ–ç ”ç©¶äº†ï¼

è®°å¾—å®šæœŸæ›´æ–°ä¾èµ–åŒ…å¹¶æ£€æŸ¥ API å¯†é’¥çš„æœ‰æ•ˆæ€§ã€‚ 