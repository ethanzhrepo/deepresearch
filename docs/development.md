# DeepResearch å¼€å‘æŒ‡å—

## ğŸ¯ æ¦‚è§ˆ

æœ¬æŒ‡å—é¢å‘å¼€å‘è€…ï¼Œä»‹ç»å¦‚ä½•æ‰©å±• DeepResearch ç³»ç»Ÿã€å¼€å‘è‡ªå®šä¹‰æ’ä»¶å’Œè´¡çŒ®ä»£ç ã€‚

## ğŸ—ï¸ å¼€å‘ç¯å¢ƒè®¾ç½®

### å…‹éš†å’Œå®‰è£…

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/your-repo/deepresearch.git
cd deepresearch

# åˆ›å»ºå¼€å‘ç¯å¢ƒ
conda create -n deepresearch-dev python=3.11 -y
conda activate deepresearch-dev

# å®‰è£…å¼€å‘ä¾èµ–
pip install -r requirements-dev.txt

# å®‰è£…é¢„æäº¤é’©å­
pre-commit install

# è¿è¡Œæµ‹è¯•
pytest
```

### å¼€å‘ä¾èµ–

```txt
# requirements-dev.txt
pytest>=7.0.0
pytest-asyncio>=0.21.0
pytest-cov>=4.0.0
black>=23.0.0
isort>=5.12.0
flake8>=6.0.0
mypy>=1.0.0
pre-commit>=3.0.0
sphinx>=6.0.0
sphinx-rtd-theme>=1.2.0
```

## ğŸ§© æ’ä»¶å¼€å‘

### åŸºç¡€æ’ä»¶ç»“æ„

```python
# plugins/example_plugin.py
from typing import Dict, Any, Optional
from abc import ABC, abstractmethod

class BasePlugin(ABC):
    """æ’ä»¶åŸºç±»"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.name = self.__class__.__name__
        self.version = "1.0.0"
        self.enabled = config.get("enabled", True)
    
    @abstractmethod
    async def initialize(self) -> bool:
        """åˆå§‹åŒ–æ’ä»¶"""
        pass
    
    @abstractmethod
    async def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œæ’ä»¶é€»è¾‘"""
        pass
    
    @abstractmethod
    async def cleanup(self) -> None:
        """æ¸…ç†èµ„æº"""
        pass
    
    def get_info(self) -> Dict[str, Any]:
        """è·å–æ’ä»¶ä¿¡æ¯"""
        return {
            "name": self.name,
            "version": self.version,
            "enabled": self.enabled,
            "description": self.__doc__ or "No description"
        }

class ExamplePlugin(BasePlugin):
    """ç¤ºä¾‹æ’ä»¶"""
    
    async def initialize(self) -> bool:
        """åˆå§‹åŒ–æ’ä»¶"""
        print(f"åˆå§‹åŒ–æ’ä»¶: {self.name}")
        return True
    
    async def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œæ’ä»¶é€»è¾‘"""
        topic = context.get("topic", "")
        
        # æ’ä»¶é€»è¾‘
        result = f"æ’ä»¶å¤„ç†ç»“æœ: {topic}"
        
        return {
            "plugin_result": result,
            "status": "success"
        }
    
    async def cleanup(self) -> None:
        """æ¸…ç†èµ„æº"""
        print(f"æ¸…ç†æ’ä»¶: {self.name}")
```

### æ’ä»¶ç®¡ç†å™¨

```python
# core/plugin_manager.py
import importlib
import inspect
from pathlib import Path
from typing import Dict, List, Any, Type
from plugins.base_plugin import BasePlugin

class PluginManager:
    """æ’ä»¶ç®¡ç†å™¨"""
    
    def __init__(self, plugin_dir: str = "plugins"):
        self.plugin_dir = Path(plugin_dir)
        self.plugins: Dict[str, BasePlugin] = {}
        self.hooks: Dict[str, List[BasePlugin]] = {}
    
    async def load_plugins(self) -> None:
        """åŠ è½½æ‰€æœ‰æ’ä»¶"""
        
        if not self.plugin_dir.exists():
            return
        
        for plugin_file in self.plugin_dir.glob("*.py"):
            if plugin_file.name.startswith("_"):
                continue
            
            await self._load_plugin_file(plugin_file)
    
    async def _load_plugin_file(self, plugin_file: Path) -> None:
        """åŠ è½½å•ä¸ªæ’ä»¶æ–‡ä»¶"""
        
        try:
            # åŠ¨æ€å¯¼å…¥æ¨¡å—
            module_name = f"plugins.{plugin_file.stem}"
            module = importlib.import_module(module_name)
            
            # æŸ¥æ‰¾æ’ä»¶ç±»
            for name, obj in inspect.getmembers(module):
                if (inspect.isclass(obj) and 
                    issubclass(obj, BasePlugin) and 
                    obj != BasePlugin):
                    
                    # åˆ›å»ºæ’ä»¶å®ä¾‹
                    config = self._get_plugin_config(name)
                    plugin = obj(config)
                    
                    if plugin.enabled:
                        await plugin.initialize()
                        self.plugins[name] = plugin
                        print(f"åŠ è½½æ’ä»¶: {name}")
        
        except Exception as e:
            print(f"åŠ è½½æ’ä»¶å¤±è´¥ {plugin_file}: {e}")
    
    def _get_plugin_config(self, plugin_name: str) -> Dict[str, Any]:
        """è·å–æ’ä»¶é…ç½®"""
        # ä»é…ç½®æ–‡ä»¶æˆ–ç¯å¢ƒå˜é‡è·å–é…ç½®
        return {
            "enabled": True,
            "debug": False
        }
    
    async def execute_hook(self, hook_name: str, context: Dict[str, Any]) -> List[Dict[str, Any]]:
        """æ‰§è¡Œé’©å­"""
        
        results = []
        
        for plugin in self.plugins.values():
            if hasattr(plugin, f"on_{hook_name}"):
                try:
                    hook_method = getattr(plugin, f"on_{hook_name}")
                    result = await hook_method(context)
                    results.append(result)
                except Exception as e:
                    print(f"æ’ä»¶ {plugin.name} æ‰§è¡Œé’©å­ {hook_name} å¤±è´¥: {e}")
        
        return results
    
    async def cleanup_all(self) -> None:
        """æ¸…ç†æ‰€æœ‰æ’ä»¶"""
        
        for plugin in self.plugins.values():
            try:
                await plugin.cleanup()
            except Exception as e:
                print(f"æ¸…ç†æ’ä»¶ {plugin.name} å¤±è´¥: {e}")
```

## ğŸ› ï¸ è‡ªå®šä¹‰å·¥å…·å¼€å‘

### å·¥å…·åŸºç±»

```python
# tools/base_tool.py
from abc import ABC, abstractmethod
from typing import Any, Dict, Optional, Union
import asyncio

class BaseTool(ABC):
    """å·¥å…·åŸºç±»"""
    
    name: str = ""
    description: str = ""
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        self.config = config or {}
        self.enabled = self.config.get("enabled", True)
    
    @abstractmethod
    def _run(self, *args, **kwargs) -> Any:
        """åŒæ­¥æ‰§è¡Œå·¥å…·"""
        pass
    
    async def _arun(self, *args, **kwargs) -> Any:
        """å¼‚æ­¥æ‰§è¡Œå·¥å…·"""
        # é»˜è®¤å®ç°ï¼šåœ¨çº¿ç¨‹æ± ä¸­è¿è¡ŒåŒæ­¥æ–¹æ³•
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(None, self._run, *args, **kwargs)
    
    def run(self, *args, **kwargs) -> Any:
        """è¿è¡Œå·¥å…·ï¼ˆåŒæ­¥ï¼‰"""
        if not self.enabled:
            raise RuntimeError(f"å·¥å…· {self.name} å·²ç¦ç”¨")
        
        return self._run(*args, **kwargs)
    
    async def arun(self, *args, **kwargs) -> Any:
        """è¿è¡Œå·¥å…·ï¼ˆå¼‚æ­¥ï¼‰"""
        if not self.enabled:
            raise RuntimeError(f"å·¥å…· {self.name} å·²ç¦ç”¨")
        
        return await self._arun(*args, **kwargs)
    
    def get_info(self) -> Dict[str, Any]:
        """è·å–å·¥å…·ä¿¡æ¯"""
        return {
            "name": self.name,
            "description": self.description,
            "enabled": self.enabled,
            "config": self.config
        }
```

### è‡ªå®šä¹‰å·¥å…·ç¤ºä¾‹

```python
# tools/custom_analyzer.py
import re
import json
from typing import Dict, Any, List
from tools.base_tool import BaseTool

class TextAnalyzer(BaseTool):
    """æ–‡æœ¬åˆ†æå·¥å…·"""
    
    name = "text_analyzer"
    description = "åˆ†ææ–‡æœ¬çš„å„ç§ç‰¹å¾"
    
    def _run(self, text: str, analysis_types: List[str] = None) -> Dict[str, Any]:
        """æ‰§è¡Œæ–‡æœ¬åˆ†æ"""
        
        if analysis_types is None:
            analysis_types = ["basic", "sentiment", "keywords"]
        
        results = {}
        
        if "basic" in analysis_types:
            results["basic"] = self._basic_analysis(text)
        
        if "sentiment" in analysis_types:
            results["sentiment"] = self._sentiment_analysis(text)
        
        if "keywords" in analysis_types:
            results["keywords"] = self._keyword_extraction(text)
        
        if "readability" in analysis_types:
            results["readability"] = self._readability_analysis(text)
        
        return results
    
    def _basic_analysis(self, text: str) -> Dict[str, Any]:
        """åŸºç¡€æ–‡æœ¬åˆ†æ"""
        
        words = text.split()
        sentences = re.split(r'[.!?]+', text)
        paragraphs = text.split('\n\n')
        
        return {
            "character_count": len(text),
            "word_count": len(words),
            "sentence_count": len([s for s in sentences if s.strip()]),
            "paragraph_count": len([p for p in paragraphs if p.strip()]),
            "avg_words_per_sentence": len(words) / max(len(sentences), 1),
            "avg_chars_per_word": len(text) / max(len(words), 1)
        }
    
    def _sentiment_analysis(self, text: str) -> Dict[str, Any]:
        """æƒ…æ„Ÿåˆ†æ"""
        
        positive_words = ["å¥½", "ä¼˜ç§€", "æˆåŠŸ", "å¢é•¿", "åˆ›æ–°", "æœ‰æ•ˆ", "é‡è¦"]
        negative_words = ["å·®", "å¤±è´¥", "ä¸‹é™", "é—®é¢˜", "å›°éš¾", "é”™è¯¯", "å±é™©"]
        
        text_lower = text.lower()
        
        positive_count = sum(1 for word in positive_words if word in text_lower)
        negative_count = sum(1 for word in negative_words if word in text_lower)
        
        total_words = len(text.split())
        sentiment_score = (positive_count - negative_count) / max(total_words, 1)
        
        if sentiment_score > 0.05:
            sentiment = "positive"
        elif sentiment_score < -0.05:
            sentiment = "negative"
        else:
            sentiment = "neutral"
        
        return {
            "sentiment": sentiment,
            "score": sentiment_score,
            "positive_indicators": positive_count,
            "negative_indicators": negative_count,
            "confidence": abs(sentiment_score)
        }
    
    def _keyword_extraction(self, text: str) -> Dict[str, Any]:
        """å…³é”®è¯æå–"""
        
        # ç®€å•çš„å…³é”®è¯æå–
        words = re.findall(r'\b\w+\b', text.lower())
        
        # è¿‡æ»¤åœç”¨è¯
        stop_words = {"çš„", "æ˜¯", "åœ¨", "æœ‰", "å’Œ", "ä¸", "æˆ–", "ä½†", "è€Œ", "äº†", "ç€", "è¿‡"}
        filtered_words = [w for w in words if w not in stop_words and len(w) > 1]
        
        # ç»Ÿè®¡è¯é¢‘
        word_freq = {}
        for word in filtered_words:
            word_freq[word] = word_freq.get(word, 0) + 1
        
        # æ’åºè·å–å…³é”®è¯
        keywords = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:10]
        
        return {
            "keywords": keywords,
            "total_unique_words": len(word_freq),
            "word_frequency": word_freq
        }
    
    def _readability_analysis(self, text: str) -> Dict[str, Any]:
        """å¯è¯»æ€§åˆ†æ"""
        
        sentences = re.split(r'[.!?]+', text)
        words = text.split()
        
        if not sentences or not words:
            return {"readability_score": 0, "level": "unknown"}
        
        avg_sentence_length = len(words) / len(sentences)
        
        # ç®€åŒ–çš„å¯è¯»æ€§è¯„åˆ†
        if avg_sentence_length <= 15:
            level = "easy"
            score = 0.9
        elif avg_sentence_length <= 25:
            level = "medium"
            score = 0.7
        else:
            level = "hard"
            score = 0.5
        
        return {
            "readability_score": score,
            "level": level,
            "avg_sentence_length": avg_sentence_length,
            "total_sentences": len(sentences),
            "total_words": len(words)
        }

class DataVisualizer(BaseTool):
    """æ•°æ®å¯è§†åŒ–å·¥å…·"""
    
    name = "data_visualizer"
    description = "åˆ›å»ºæ•°æ®å¯è§†åŒ–å›¾è¡¨"
    
    def _run(self, data: Dict[str, Any], chart_type: str = "bar") -> str:
        """ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨"""
        
        try:
            import matplotlib.pyplot as plt
            import json
            from pathlib import Path
            
            # åˆ›å»ºå›¾è¡¨
            fig, ax = plt.subplots(figsize=(10, 6))
            
            if chart_type == "bar":
                self._create_bar_chart(ax, data)
            elif chart_type == "line":
                self._create_line_chart(ax, data)
            elif chart_type == "pie":
                self._create_pie_chart(ax, data)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„å›¾è¡¨ç±»å‹: {chart_type}")
            
            # ä¿å­˜å›¾è¡¨
            output_dir = Path("output/charts")
            output_dir.mkdir(parents=True, exist_ok=True)
            
            chart_file = output_dir / f"chart_{chart_type}.png"
            plt.savefig(chart_file, dpi=300, bbox_inches='tight')
            plt.close()
            
            return str(chart_file)
        
        except ImportError:
            return "é”™è¯¯: éœ€è¦å®‰è£… matplotlib"
        except Exception as e:
            return f"ç”Ÿæˆå›¾è¡¨å¤±è´¥: {e}"
    
    def _create_bar_chart(self, ax, data):
        """åˆ›å»ºæŸ±çŠ¶å›¾"""
        if "x" in data and "y" in data:
            ax.bar(data["x"], data["y"])
            ax.set_xlabel("Xè½´")
            ax.set_ylabel("Yè½´")
            ax.set_title("æŸ±çŠ¶å›¾")
    
    def _create_line_chart(self, ax, data):
        """åˆ›å»ºæŠ˜çº¿å›¾"""
        if "x" in data and "y" in data:
            ax.plot(data["x"], data["y"], marker='o')
            ax.set_xlabel("Xè½´")
            ax.set_ylabel("Yè½´")
            ax.set_title("æŠ˜çº¿å›¾")
            ax.grid(True)
    
    def _create_pie_chart(self, ax, data):
        """åˆ›å»ºé¥¼å›¾"""
        if "labels" in data and "values" in data:
            ax.pie(data["values"], labels=data["labels"], autopct='%1.1f%%')
            ax.set_title("é¥¼å›¾")
```

### å·¥å…·æ³¨å†Œ

```python
# tools/registry.py
from typing import Dict, List, Type, Optional
from tools.base_tool import BaseTool

class ToolRegistry:
    """å·¥å…·æ³¨å†Œè¡¨"""
    
    def __init__(self):
        self._tools: Dict[str, Type[BaseTool]] = {}
        self._instances: Dict[str, BaseTool] = {}
    
    def register(self, tool_class: Type[BaseTool]) -> None:
        """æ³¨å†Œå·¥å…·ç±»"""
        if not issubclass(tool_class, BaseTool):
            raise ValueError("å·¥å…·å¿…é¡»ç»§æ‰¿è‡ª BaseTool")
        
        tool_name = tool_class.name or tool_class.__name__.lower()
        self._tools[tool_name] = tool_class
        print(f"æ³¨å†Œå·¥å…·: {tool_name}")
    
    def get_tool(self, name: str, config: Optional[Dict] = None) -> BaseTool:
        """è·å–å·¥å…·å®ä¾‹"""
        if name not in self._tools:
            raise ValueError(f"æœªæ‰¾åˆ°å·¥å…·: {name}")
        
        # ä½¿ç”¨ç¼“å­˜çš„å®ä¾‹æˆ–åˆ›å»ºæ–°å®ä¾‹
        cache_key = f"{name}_{hash(str(config))}"
        
        if cache_key not in self._instances:
            tool_class = self._tools[name]
            self._instances[cache_key] = tool_class(config)
        
        return self._instances[cache_key]
    
    def list_tools(self) -> List[str]:
        """åˆ—å‡ºæ‰€æœ‰æ³¨å†Œçš„å·¥å…·"""
        return list(self._tools.keys())
    
    def get_tool_info(self, name: str) -> Dict:
        """è·å–å·¥å…·ä¿¡æ¯"""
        if name not in self._tools:
            raise ValueError(f"æœªæ‰¾åˆ°å·¥å…·: {name}")
        
        tool_class = self._tools[name]
        return {
            "name": tool_class.name or name,
            "description": tool_class.description,
            "class": tool_class.__name__
        }

# å…¨å±€å·¥å…·æ³¨å†Œè¡¨
tool_registry = ToolRegistry()

# æ³¨å†Œå†…ç½®å·¥å…·
from tools.custom_analyzer import TextAnalyzer, DataVisualizer

tool_registry.register(TextAnalyzer)
tool_registry.register(DataVisualizer)
```

## ğŸ¤– è‡ªå®šä¹‰ Agent å¼€å‘

### Agent åŸºç±»

```python
# agents/base_agent.py
from abc import ABC, abstractmethod
from typing import Any, Dict, List, Optional
from llm.base import BaseLLM
from tools.registry import tool_registry

class BaseAgent(ABC):
    """Agent åŸºç±»"""
    
    def __init__(self, 
                 llm: BaseLLM,
                 tools: Optional[List[str]] = None,
                 config: Optional[Dict[str, Any]] = None):
        self.llm = llm
        self.config = config or {}
        self.tools = {}
        
        # åˆå§‹åŒ–å·¥å…·
        if tools:
            for tool_name in tools:
                self.tools[tool_name] = tool_registry.get_tool(tool_name)
    
    @abstractmethod
    async def execute(self, input_data: Any) -> Any:
        """æ‰§è¡Œ Agent ä»»åŠ¡"""
        pass
    
    async def use_tool(self, tool_name: str, *args, **kwargs) -> Any:
        """ä½¿ç”¨å·¥å…·"""
        if tool_name not in self.tools:
            raise ValueError(f"Agent æœªé…ç½®å·¥å…·: {tool_name}")
        
        tool = self.tools[tool_name]
        return await tool.arun(*args, **kwargs)
    
    def get_available_tools(self) -> List[str]:
        """è·å–å¯ç”¨å·¥å…·åˆ—è¡¨"""
        return list(self.tools.keys())

class CustomAnalysisAgent(BaseAgent):
    """è‡ªå®šä¹‰åˆ†æ Agent"""
    
    async def execute(self, text: str) -> Dict[str, Any]:
        """æ‰§è¡Œæ–‡æœ¬åˆ†æ"""
        
        # ä½¿ç”¨æ–‡æœ¬åˆ†æå·¥å…·
        analysis_result = await self.use_tool(
            "text_analyzer", 
            text, 
            ["basic", "sentiment", "keywords", "readability"]
        )
        
        # ä½¿ç”¨ LLM ç”Ÿæˆåˆ†ææŠ¥å‘Š
        prompt = f"""
        åŸºäºä»¥ä¸‹æ–‡æœ¬åˆ†æç»“æœï¼Œç”Ÿæˆä¸€ä»½è¯¦ç»†çš„åˆ†ææŠ¥å‘Šï¼š
        
        åˆ†æç»“æœï¼š
        {analysis_result}
        
        åŸæ–‡æœ¬ï¼š
        {text[:500]}...
        
        è¯·æä¾›ï¼š
        1. æ–‡æœ¬ç‰¹å¾æ€»ç»“
        2. æƒ…æ„Ÿå€¾å‘åˆ†æ
        3. å…³é”®ä¸»é¢˜è¯†åˆ«
        4. å¯è¯»æ€§è¯„ä¼°
        5. æ”¹è¿›å»ºè®®
        """
        
        report = await self.llm.agenerate([prompt])
        
        return {
            "analysis_data": analysis_result,
            "analysis_report": report.generations[0][0].text,
            "agent": self.__class__.__name__
        }
```

## ğŸ”„ å·¥ä½œæµæ‰©å±•

### è‡ªå®šä¹‰å·¥ä½œæµèŠ‚ç‚¹

```python
# workflow/custom_nodes.py
from typing import Dict, Any
from workflow.base_node import BaseNode

class DataCollectionNode(BaseNode):
    """æ•°æ®æ”¶é›†èŠ‚ç‚¹"""
    
    async def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œæ•°æ®æ”¶é›†"""
        
        topic = context.get("topic", "")
        
        # å¤šæºæ•°æ®æ”¶é›†
        search_results = await self._search_web(topic)
        academic_papers = await self._search_academic(topic)
        news_articles = await self._search_news(topic)
        
        collected_data = {
            "web_results": search_results,
            "academic_papers": academic_papers,
            "news_articles": news_articles,
            "collection_timestamp": self._get_timestamp()
        }
        
        context["collected_data"] = collected_data
        return context
    
    async def _search_web(self, topic: str) -> List[Dict]:
        """æœç´¢ç½‘é¡µ"""
        # å®ç°ç½‘é¡µæœç´¢é€»è¾‘
        return []
    
    async def _search_academic(self, topic: str) -> List[Dict]:
        """æœç´¢å­¦æœ¯è®ºæ–‡"""
        # å®ç°å­¦æœ¯æœç´¢é€»è¾‘
        return []
    
    async def _search_news(self, topic: str) -> List[Dict]:
        """æœç´¢æ–°é—»æ–‡ç« """
        # å®ç°æ–°é—»æœç´¢é€»è¾‘
        return []

class QualityAssuranceNode(BaseNode):
    """è´¨é‡ä¿è¯èŠ‚ç‚¹"""
    
    async def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œè´¨é‡æ£€æŸ¥"""
        
        content = context.get("content", "")
        
        # è´¨é‡æ£€æŸ¥
        quality_score = await self._assess_quality(content)
        
        if quality_score < 0.7:
            # è´¨é‡ä¸è¾¾æ ‡ï¼Œè§¦å‘æ”¹è¿›æµç¨‹
            improved_content = await self._improve_content(content)
            context["content"] = improved_content
            context["quality_improved"] = True
        
        context["quality_score"] = quality_score
        return context
    
    async def _assess_quality(self, content: str) -> float:
        """è¯„ä¼°å†…å®¹è´¨é‡"""
        # å®ç°è´¨é‡è¯„ä¼°é€»è¾‘
        return 0.8
    
    async def _improve_content(self, content: str) -> str:
        """æ”¹è¿›å†…å®¹"""
        # å®ç°å†…å®¹æ”¹è¿›é€»è¾‘
        return content
```

### å·¥ä½œæµç¼–æ’

```python
# workflow/custom_workflow.py
from typing import List, Dict, Any
from workflow.base_workflow import BaseWorkflow
from workflow.custom_nodes import DataCollectionNode, QualityAssuranceNode

class EnhancedResearchWorkflow(BaseWorkflow):
    """å¢å¼ºç ”ç©¶å·¥ä½œæµ"""
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__(config)
        self.setup_nodes()
    
    def setup_nodes(self):
        """è®¾ç½®å·¥ä½œæµèŠ‚ç‚¹"""
        
        # æ·»åŠ è‡ªå®šä¹‰èŠ‚ç‚¹
        self.add_node("data_collection", DataCollectionNode())
        self.add_node("quality_assurance", QualityAssuranceNode())
        
        # å®šä¹‰èŠ‚ç‚¹æ‰§è¡Œé¡ºåº
        self.add_edge("start", "data_collection")
        self.add_edge("data_collection", "outline_generation")
        self.add_edge("outline_generation", "content_generation")
        self.add_edge("content_generation", "quality_assurance")
        self.add_edge("quality_assurance", "end")
        
        # æ¡ä»¶åˆ†æ”¯
        self.add_conditional_edge(
            "quality_assurance",
            self._should_improve_quality,
            {
                True: "content_generation",  # é‡æ–°ç”Ÿæˆå†…å®¹
                False: "end"                 # ç»“æŸæµç¨‹
            }
        )
    
    def _should_improve_quality(self, context: Dict[str, Any]) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦æ”¹è¿›è´¨é‡"""
        quality_score = context.get("quality_score", 0)
        return quality_score < 0.8
```

## ğŸ§ª æµ‹è¯•å¼€å‘

### å•å…ƒæµ‹è¯•

```python
# tests/test_custom_tools.py
import pytest
from tools.custom_analyzer import TextAnalyzer, DataVisualizer

class TestTextAnalyzer:
    """æ–‡æœ¬åˆ†æå·¥å…·æµ‹è¯•"""
    
    @pytest.fixture
    def analyzer(self):
        return TextAnalyzer()
    
    def test_basic_analysis(self, analyzer):
        """æµ‹è¯•åŸºç¡€åˆ†æ"""
        text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬ã€‚å®ƒåŒ…å«ä¸¤ä¸ªå¥å­ã€‚"
        result = analyzer._basic_analysis(text)
        
        assert result["word_count"] > 0
        assert result["sentence_count"] == 2
        assert result["character_count"] == len(text)
    
    def test_sentiment_analysis(self, analyzer):
        """æµ‹è¯•æƒ…æ„Ÿåˆ†æ"""
        positive_text = "è¿™æ˜¯ä¸€ä¸ªéå¸¸å¥½çš„äº§å“ï¼Œæ•ˆæœä¼˜ç§€ã€‚"
        negative_text = "è¿™ä¸ªäº§å“å¾ˆå·®ï¼Œå­˜åœ¨å¾ˆå¤šé—®é¢˜ã€‚"
        
        positive_result = analyzer._sentiment_analysis(positive_text)
        negative_result = analyzer._sentiment_analysis(negative_text)
        
        assert positive_result["sentiment"] == "positive"
        assert negative_result["sentiment"] == "negative"
    
    @pytest.mark.asyncio
    async def test_async_run(self, analyzer):
        """æµ‹è¯•å¼‚æ­¥è¿è¡Œ"""
        text = "æµ‹è¯•å¼‚æ­¥æ‰§è¡ŒåŠŸèƒ½ã€‚"
        result = await analyzer.arun(text, ["basic"])
        
        assert "basic" in result
        assert result["basic"]["word_count"] > 0

class TestDataVisualizer:
    """æ•°æ®å¯è§†åŒ–å·¥å…·æµ‹è¯•"""
    
    @pytest.fixture
    def visualizer(self):
        return DataVisualizer()
    
    def test_bar_chart_creation(self, visualizer):
        """æµ‹è¯•æŸ±çŠ¶å›¾åˆ›å»º"""
        data = {
            "x": ["A", "B", "C"],
            "y": [1, 2, 3]
        }
        
        result = visualizer._run(data, "bar")
        assert "chart_bar.png" in result
```

### é›†æˆæµ‹è¯•

```python
# tests/test_integration.py
import pytest
from workflow.custom_workflow import EnhancedResearchWorkflow

class TestEnhancedWorkflow:
    """å¢å¼ºå·¥ä½œæµé›†æˆæµ‹è¯•"""
    
    @pytest.fixture
    def workflow(self):
        config = {
            "llm_provider": "openai",
            "max_sections": 5,
            "quality_threshold": 0.8
        }
        return EnhancedResearchWorkflow(config)
    
    @pytest.mark.asyncio
    async def test_full_workflow(self, workflow):
        """æµ‹è¯•å®Œæ•´å·¥ä½œæµ"""
        topic = "äººå·¥æ™ºèƒ½å‘å±•è¶‹åŠ¿"
        
        result = await workflow.run({"topic": topic})
        
        assert "content" in result
        assert "quality_score" in result
        assert result["quality_score"] >= 0.7
    
    @pytest.mark.asyncio
    async def test_quality_improvement_loop(self, workflow):
        """æµ‹è¯•è´¨é‡æ”¹è¿›å¾ªç¯"""
        # æ¨¡æ‹Ÿä½è´¨é‡å†…å®¹
        context = {
            "topic": "æµ‹è¯•ä¸»é¢˜",
            "content": "ä½è´¨é‡å†…å®¹",
            "quality_score": 0.5
        }
        
        # åº”è¯¥è§¦å‘æ”¹è¿›æµç¨‹
        should_improve = workflow._should_improve_quality(context)
        assert should_improve is True
```

## ğŸ“¦ æ‰“åŒ…å’Œåˆ†å‘

### åˆ›å»ºæ’ä»¶åŒ…

```python
# setup.py
from setuptools import setup, find_packages

setup(
    name="deepresearch-custom-plugin",
    version="1.0.0",
    description="DeepResearch è‡ªå®šä¹‰æ’ä»¶",
    author="Your Name",
    author_email="your.email@example.com",
    packages=find_packages(),
    install_requires=[
        "deepresearch>=2.0.0",
    ],
    entry_points={
        "deepresearch.plugins": [
            "custom_plugin = plugins.custom_plugin:CustomPlugin",
        ],
        "deepresearch.tools": [
            "text_analyzer = tools.custom_analyzer:TextAnalyzer",
            "data_visualizer = tools.custom_analyzer:DataVisualizer",
        ]
    },
    classifiers=[
        "Development Status :: 4 - Beta",
        "Intended Audience :: Developers",
        "License :: OSI Approved :: MIT License",
        "Programming Language :: Python :: 3.8",
        "Programming Language :: Python :: 3.9",
        "Programming Language :: Python :: 3.10",
        "Programming Language :: Python :: 3.11",
    ],
    python_requires=">=3.8",
)
```

### æ’ä»¶é…ç½®

```yaml
# plugin_config.yml
plugin:
  name: "custom_research_plugin"
  version: "1.0.0"
  description: "è‡ªå®šä¹‰ç ”ç©¶æ’ä»¶"
  
  dependencies:
    - "matplotlib>=3.5.0"
    - "pandas>=1.3.0"
  
  hooks:
    - "before_research"
    - "after_outline_generation"
    - "before_content_generation"
    - "after_research"
  
  tools:
    - "text_analyzer"
    - "data_visualizer"
  
  configuration:
    enable_advanced_analysis: true
    visualization_format: "png"
    quality_threshold: 0.8
```

## ğŸ”§ è°ƒè¯•å’Œæ€§èƒ½ä¼˜åŒ–

### è°ƒè¯•å·¥å…·

```python
# debug/profiler.py
import cProfile
import pstats
import functools
from typing import Callable

def profile_function(func: Callable) -> Callable:
    """å‡½æ•°æ€§èƒ½åˆ†æè£…é¥°å™¨"""
    
    @functools.wraps(func)
    def wrapper(*args, **kwargs):
        profiler = cProfile.Profile()
        profiler.enable()
        
        try:
            result = func(*args, **kwargs)
            return result
        finally:
            profiler.disable()
            
            # ä¿å­˜åˆ†æç»“æœ
            stats = pstats.Stats(profiler)
            stats.sort_stats('cumulative')
            stats.print_stats(20)  # æ˜¾ç¤ºå‰20ä¸ªæœ€è€—æ—¶çš„å‡½æ•°
    
    return wrapper

# ä½¿ç”¨ç¤ºä¾‹
@profile_function
def expensive_function():
    """è€—æ—¶å‡½æ•°"""
    import time
    time.sleep(1)
    return "å®Œæˆ"
```

### å†…å­˜ç›‘æ§

```python
# debug/memory_monitor.py
import psutil
import tracemalloc
from typing import Dict, Any

class MemoryMonitor:
    """å†…å­˜ç›‘æ§å™¨"""
    
    def __init__(self):
        self.start_memory = None
        self.peak_memory = 0
    
    def start(self):
        """å¼€å§‹ç›‘æ§"""
        tracemalloc.start()
        self.start_memory = psutil.Process().memory_info().rss
    
    def get_current_usage(self) -> Dict[str, Any]:
        """è·å–å½“å‰å†…å­˜ä½¿ç”¨"""
        current_memory = psutil.Process().memory_info().rss
        
        if tracemalloc.is_tracing():
            current, peak = tracemalloc.get_traced_memory()
            
            return {
                "current_rss": current_memory,
                "start_rss": self.start_memory,
                "memory_increase": current_memory - self.start_memory,
                "traced_current": current,
                "traced_peak": peak
            }
        
        return {
            "current_rss": current_memory,
            "start_rss": self.start_memory,
            "memory_increase": current_memory - self.start_memory
        }
    
    def stop(self) -> Dict[str, Any]:
        """åœæ­¢ç›‘æ§å¹¶è¿”å›ç»Ÿè®¡"""
        usage = self.get_current_usage()
        
        if tracemalloc.is_tracing():
            tracemalloc.stop()
        
        return usage

# ä½¿ç”¨ç¤ºä¾‹
monitor = MemoryMonitor()
monitor.start()

# æ‰§è¡Œä»£ç ...

usage = monitor.stop()
print(f"å†…å­˜ä½¿ç”¨å¢åŠ : {usage['memory_increase'] / 1024 / 1024:.2f} MB")
```

## ğŸ“š æ–‡æ¡£ç”Ÿæˆ

### API æ–‡æ¡£

```python
# docs/generate_docs.py
import inspect
import json
from pathlib import Path
from typing import Dict, Any, List

def generate_api_docs(module_path: str, output_dir: str):
    """ç”Ÿæˆ API æ–‡æ¡£"""
    
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    # æ‰«ææ¨¡å—
    modules = _scan_modules(module_path)
    
    for module_name, module in modules.items():
        doc_data = _extract_module_docs(module)
        
        # ç”Ÿæˆ Markdown æ–‡æ¡£
        markdown_content = _generate_markdown(module_name, doc_data)
        
        doc_file = output_path / f"{module_name}.md"
        with open(doc_file, 'w', encoding='utf-8') as f:
            f.write(markdown_content)
    
    print(f"API æ–‡æ¡£å·²ç”Ÿæˆåˆ°: {output_dir}")

def _extract_module_docs(module) -> Dict[str, Any]:
    """æå–æ¨¡å—æ–‡æ¡£"""
    
    classes = []
    functions = []
    
    for name, obj in inspect.getmembers(module):
        if inspect.isclass(obj):
            classes.append(_extract_class_docs(obj))
        elif inspect.isfunction(obj):
            functions.append(_extract_function_docs(obj))
    
    return {
        "module_doc": inspect.getdoc(module),
        "classes": classes,
        "functions": functions
    }

def _extract_class_docs(cls) -> Dict[str, Any]:
    """æå–ç±»æ–‡æ¡£"""
    
    methods = []
    for name, method in inspect.getmembers(cls, inspect.ismethod):
        if not name.startswith('_'):
            methods.append(_extract_function_docs(method))
    
    return {
        "name": cls.__name__,
        "doc": inspect.getdoc(cls),
        "methods": methods
    }

def _extract_function_docs(func) -> Dict[str, Any]:
    """æå–å‡½æ•°æ–‡æ¡£"""
    
    signature = inspect.signature(func)
    
    return {
        "name": func.__name__,
        "doc": inspect.getdoc(func),
        "signature": str(signature),
        "parameters": [
            {
                "name": param.name,
                "type": str(param.annotation) if param.annotation != param.empty else "Any",
                "default": str(param.default) if param.default != param.empty else None
            }
            for param in signature.parameters.values()
        ]
    }
```

---

**é€šè¿‡è¿™äº›å¼€å‘æŒ‡å—ï¼Œæ‚¨å¯ä»¥è½»æ¾æ‰©å±• DeepResearch çš„åŠŸèƒ½ï¼** ğŸ› ï¸âœ¨ 