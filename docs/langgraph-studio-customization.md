# ğŸ¨ LangGraph Studio è‡ªå®šä¹‰ç ”ç©¶æµç¨‹æŒ‡å—

## ğŸ“‹ æ¦‚è§ˆ

LangGraph Studio æ˜¯ä¸€ä¸ªä¸“é—¨ä¸ºæ™ºèƒ½ä»£ç†å¼€å‘è®¾è®¡çš„IDEï¼Œå®ƒæä¾›äº†å¯è§†åŒ–ã€äº¤äº’å¼è°ƒè¯•å’Œå®æ—¶çŠ¶æ€ç®¡ç†åŠŸèƒ½ã€‚æœ¬æŒ‡å—å°†è¯¦ç»†ä»‹ç»å¦‚ä½•ä½¿ç”¨ LangGraph Studio æ¥è‡ªå®šä¹‰ DeepResearch çš„ç ”ç©¶å·¥ä½œæµã€‚

## ğŸ¯ å­¦ä¹ ç›®æ ‡

é€šè¿‡æœ¬æŒ‡å—ï¼Œæ‚¨å°†å­¦ä¼šï¼š
- ğŸ—ï¸ å¦‚ä½•åœ¨ LangGraph Studio ä¸­å¯è§†åŒ–ç ”ç©¶å·¥ä½œæµ
- ğŸ”§ å¦‚ä½•è‡ªå®šä¹‰å’Œä¿®æ”¹ç ”ç©¶æµç¨‹èŠ‚ç‚¹
- ğŸ® å¦‚ä½•ä½¿ç”¨äº¤äº’å¼è°ƒè¯•åŠŸèƒ½
- ğŸ“Š å¦‚ä½•ç®¡ç†å’Œä¿®æ”¹å·¥ä½œæµçŠ¶æ€
- ğŸš€ å¦‚ä½•ä¼˜åŒ–ç ”ç©¶æµç¨‹æ€§èƒ½
- ğŸ”„ å¦‚ä½•åˆ›å»ºè‡ªå®šä¹‰ç ”ç©¶æ¨¡æ¿

## ğŸ› ï¸ å®‰è£…å’Œè®¾ç½®

### 1. å®‰è£… LangGraph Studio

#### ä¸‹è½½ LangGraph Studio
```bash
# è®¿é—®å®˜æ–¹ä¸‹è½½é¡µé¢ï¼ˆå½“å‰ä»…æ”¯æŒ Apple Siliconï¼‰
# https://github.com/langchain-ai/langgraph-studio/releases

# ä¸‹è½½å¹¶å®‰è£… .dmg æ–‡ä»¶
```

#### ç³»ç»Ÿè¦æ±‚
- **æ“ä½œç³»ç»Ÿ**: macOS (Apple Silicon) - å…¶ä»–å¹³å°æ”¯æŒå³å°†æ¨å‡º
- **å†…å­˜**: è‡³å°‘ 8GB RAMï¼Œæ¨è 16GB+
- **å­˜å‚¨**: è‡³å°‘ 2GB å¯ç”¨ç©ºé—´
- **ç½‘ç»œ**: éœ€è¦äº’è”ç½‘è¿æ¥è®¿é—® LangSmith

### 2. é…ç½® LangSmith è´¦æˆ·

```bash
# 1. è®¿é—® LangSmith æ³¨å†Œ
# https://smith.langchain.com/

# 2. è·å– API å¯†é’¥
# åœ¨ LangSmith æ§åˆ¶å°ä¸­ç”Ÿæˆ API å¯†é’¥

# 3. è®¾ç½®ç¯å¢ƒå˜é‡
export LANGCHAIN_TRACING_V2=true
export LANGCHAIN_API_KEY="ä½ çš„LangSmith APIå¯†é’¥"
export LANGCHAIN_PROJECT="DeepResearch-Studio"
```

### 3. é…ç½® DeepResearch é¡¹ç›®

#### åˆ›å»º langgraph.json é…ç½®æ–‡ä»¶
```json
{
  "dependencies": [
    "langchain-openai",
    "langchain-anthropic", 
    "langchain-google-genai",
    "langchain-community",
    "langgraph",
    "tavily-python",
    "duckduckgo-search",
    "arxiv",
    "playwright",
    "browser-use"
  ],
  "graphs": {
    "research_workflow": {
      "file": "workflow/graph.py",
      "class": "ResearchWorkflow",
      "description": "DeepResearch ä¸»è¦ç ”ç©¶å·¥ä½œæµ"
    }
  },
  "env": ".env",
  "dockerfile": "Dockerfile.studio"
}
```

#### æ›´æ–°å·¥ä½œæµä»¥æ”¯æŒ Studio
```python
# workflow/studio_graph.py
"""
ä¸“ä¸º LangGraph Studio ä¼˜åŒ–çš„ç ”ç©¶å·¥ä½œæµ
"""

import asyncio
from typing import Dict, Any, List, Optional, TypedDict, Literal
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.checkpoint.memory import MemorySaver

# Studio ä¸“ç”¨çŠ¶æ€å®šä¹‰
class StudioResearchState(TypedDict):
    """Studio ä¼˜åŒ–çš„ç ”ç©¶çŠ¶æ€"""
    # åŸºç¡€ä¿¡æ¯
    topic: str
    research_depth: Literal["basic", "intermediate", "advanced"]
    language: str
    
    # å¤§çº²ç›¸å…³
    outline: Optional[Dict[str, Any]]
    outline_approved: bool
    outline_feedback: Optional[str]
    
    # å†…å®¹ç”Ÿæˆ
    current_section: int
    current_subsection: int
    content_map: Dict[str, Any]
    
    # æœç´¢å’Œå·¥å…·
    search_results: List[Dict[str, Any]]
    tools_enabled: List[str]
    
    # æµç¨‹æ§åˆ¶
    stage: Literal["init", "outline", "search", "content", "review", "complete"]
    error_message: Optional[str]
    debug_info: Dict[str, Any]
    
    # Studio ç‰¹æœ‰
    user_interventions: List[Dict[str, Any]]
    performance_metrics: Dict[str, Any]

class StudioResearchWorkflow:
    """Studio ä¼˜åŒ–çš„ç ”ç©¶å·¥ä½œæµ"""
    
    def __init__(self):
        self.memory = MemorySaver()
        self.graph = self._build_studio_graph()
    
    def _build_studio_graph(self) -> StateGraph:
        """æ„å»ºé€‚ç”¨äº Studio çš„ç ”ç©¶å›¾"""
        
        workflow = StateGraph(StudioResearchState)
        
        # æ·»åŠ æ‰€æœ‰èŠ‚ç‚¹
        workflow.add_node("initialize", self._initialize_node)
        workflow.add_node("generate_outline", self._generate_outline_node)
        workflow.add_node("review_outline", self._review_outline_node)
        workflow.add_node("search_information", self._search_information_node)
        workflow.add_node("generate_content", self._generate_content_node)
        workflow.add_node("review_content", self._review_content_node)
        workflow.add_node("finalize_report", self._finalize_report_node)
        workflow.add_node("handle_error", self._handle_error_node)
        
        # è®¾ç½®å…¥å£ç‚¹
        workflow.set_entry_point("initialize")
        
        # æ·»åŠ è¾¹å’Œæ¡ä»¶è¾¹
        workflow.add_edge("initialize", "generate_outline")
        
        # å¤§çº²å®¡æ ¸çš„æ¡ä»¶åˆ†æ”¯
        workflow.add_conditional_edges(
            "generate_outline",
            self._should_review_outline,
            {
                "review": "review_outline",
                "approve": "search_information",
                "error": "handle_error"
            }
        )
        
        workflow.add_conditional_edges(
            "review_outline", 
            self._outline_review_decision,
            {
                "regenerate": "generate_outline",
                "approve": "search_information",
                "error": "handle_error"
            }
        )
        
        # å†…å®¹ç”Ÿæˆæµç¨‹
        workflow.add_edge("search_information", "generate_content")
        workflow.add_edge("generate_content", "review_content")
        
        workflow.add_conditional_edges(
            "review_content",
            self._content_review_decision,
            {
                "revise": "generate_content", 
                "finalize": "finalize_report",
                "error": "handle_error"
            }
        )
        
        # ç»“æŸèŠ‚ç‚¹
        workflow.add_edge("finalize_report", END)
        workflow.add_edge("handle_error", END)
        
        return workflow.compile(checkpointer=self.memory)
    
    async def _initialize_node(self, state: StudioResearchState) -> StudioResearchState:
        """åˆå§‹åŒ–ç ”ç©¶æµç¨‹"""
        return {
            **state,
            "stage": "init",
            "current_section": 0,
            "current_subsection": 0,
            "content_map": {},
            "search_results": [],
            "user_interventions": [],
            "performance_metrics": {
                "start_time": asyncio.get_event_loop().time(),
                "node_execution_times": {}
            },
            "debug_info": {
                "initialized": True,
                "config": {
                    "research_depth": state.get("research_depth", "intermediate"),
                    "language": state.get("language", "zh-CN")
                }
            }
        }
    
    # ... å…¶ä»–èŠ‚ç‚¹å®ç°
```

## ğŸ¨ Studio ç•Œé¢æ¦‚è§ˆ

### ä¸»è¦ç»„ä»¶

#### 1. å›¾å¯è§†åŒ–é¢æ¿
- **èŠ‚ç‚¹è§†å›¾**: æ˜¾ç¤ºå·¥ä½œæµä¸­çš„æ‰€æœ‰èŠ‚ç‚¹å’Œè¿æ¥
- **çŠ¶æ€æŒ‡ç¤ºå™¨**: å®æ—¶æ˜¾ç¤ºæ¯ä¸ªèŠ‚ç‚¹çš„æ‰§è¡ŒçŠ¶æ€
- **æµç¨‹è¿½è¸ª**: å¯è§†åŒ–æ•°æ®æµå’Œæ‰§è¡Œè·¯å¾„

#### 2. äº¤äº’æ§åˆ¶é¢æ¿  
- **è¾“å…¥åŒºåŸŸ**: è¾“å…¥ç ”ç©¶ä¸»é¢˜å’Œå‚æ•°
- **æ§åˆ¶æŒ‰é’®**: å¯åŠ¨ã€æš‚åœã€é‡ç½®å·¥ä½œæµ
- **è°ƒè¯•é€‰é¡¹**: æ–­ç‚¹ã€å•æ­¥æ‰§è¡Œã€çŠ¶æ€æ£€æŸ¥

#### 3. çŠ¶æ€ç›‘æ§é¢æ¿
- **å½“å‰çŠ¶æ€**: æ˜¾ç¤ºå·¥ä½œæµçš„å®æ—¶çŠ¶æ€
- **å†å²è®°å½•**: çŠ¶æ€å˜åŒ–çš„æ—¶é—´çº¿
- **æ€§èƒ½æŒ‡æ ‡**: æ‰§è¡Œæ—¶é—´ã€å†…å­˜ä½¿ç”¨ç­‰

#### 4. æ—¥å¿—å’Œè°ƒè¯•é¢æ¿
- **æ‰§è¡Œæ—¥å¿—**: è¯¦ç»†çš„æ‰§è¡Œä¿¡æ¯
- **é”™è¯¯ä¿¡æ¯**: å¼‚å¸¸å’Œé”™è¯¯è¯¦æƒ…  
- **è°ƒè¯•æ•°æ®**: å˜é‡å€¼ã€å‡½æ•°è°ƒç”¨ç­‰

## ğŸ”§ è‡ªå®šä¹‰ç ”ç©¶æµç¨‹

### 1. ä¿®æ”¹å·¥ä½œæµèŠ‚ç‚¹

#### æ·»åŠ æ–°çš„ç ”ç©¶èŠ‚ç‚¹
```python
# åœ¨ Studio ä¸­æ·»åŠ è‡ªå®šä¹‰èŠ‚ç‚¹

async def _custom_analysis_node(self, state: StudioResearchState) -> StudioResearchState:
    """è‡ªå®šä¹‰åˆ†æèŠ‚ç‚¹"""
    
    # å¯ä»¥åœ¨ Studio ä¸­å®æ—¶æŸ¥çœ‹æ­¤èŠ‚ç‚¹çš„æ‰§è¡Œ
    print(f"[Studio Debug] æ‰§è¡Œè‡ªå®šä¹‰åˆ†æ: {state['topic']}")
    
    # æ‰§è¡Œè‡ªå®šä¹‰åˆ†æé€»è¾‘
    analysis_results = await self._perform_custom_analysis(state)
    
    # æ›´æ–°çŠ¶æ€ï¼ˆåœ¨ Studio ä¸­å¯è§†åŒ–ï¼‰
    return {
        **state,
        "debug_info": {
            **state.get("debug_info", {}),
            "custom_analysis": analysis_results,
            "node_completed": "custom_analysis"
        }
    }

# å°†èŠ‚ç‚¹æ·»åŠ åˆ°å·¥ä½œæµ
workflow.add_node("custom_analysis", self._custom_analysis_node)
workflow.add_edge("search_information", "custom_analysis")
workflow.add_edge("custom_analysis", "generate_content")
```

#### ä¿®æ”¹ç°æœ‰èŠ‚ç‚¹
```python
async def _enhanced_outline_node(self, state: StudioResearchState) -> StudioResearchState:
    """å¢å¼ºçš„å¤§çº²ç”ŸæˆèŠ‚ç‚¹"""
    
    # åœ¨ Studio ä¸­å¯ä»¥æš‚åœè¿™é‡Œè¿›è¡Œè°ƒè¯•
    if state.get("debug_mode"):
        print(f"[Studio Breakpoint] å¤§çº²ç”ŸæˆèŠ‚ç‚¹ - ä¸»é¢˜: {state['topic']}")
    
    # æ ¹æ®ç ”ç©¶æ·±åº¦è°ƒæ•´å¤§çº²å¤æ‚åº¦
    depth = state.get("research_depth", "intermediate")
    section_count = {
        "basic": 3,
        "intermediate": 5, 
        "advanced": 8
    }[depth]
    
    # ç”Ÿæˆå¤§çº²
    outline = await self._generate_detailed_outline(
        topic=state["topic"],
        section_count=section_count,
        language=state["language"]
    )
    
    return {
        **state,
        "outline": outline,
        "stage": "outline",
        "debug_info": {
            **state.get("debug_info", {}),
            "outline_complexity": depth,
            "section_count": section_count
        }
    }
```

### 2. åˆ›å»ºæ¡ä»¶åˆ†æ”¯

#### æ™ºèƒ½è·¯ç”±é€»è¾‘
```python
def _intelligent_routing(self, state: StudioResearchState) -> str:
    """æ™ºèƒ½è·¯ç”±å†³ç­–"""
    
    # åœ¨ Studio ä¸­å¯è§†åŒ–å†³ç­–è¿‡ç¨‹
    topic = state["topic"]
    
    # å­¦æœ¯ç ”ç©¶è·¯å¾„
    if any(keyword in topic.lower() for keyword in ["è®ºæ–‡", "å­¦æœ¯", "ç ”ç©¶", "ç§‘å­¦"]):
        return "academic_research_path"
    
    # å•†ä¸šåˆ†æè·¯å¾„  
    elif any(keyword in topic.lower() for keyword in ["å¸‚åœº", "å•†ä¸š", "ç«äº‰", "è¡Œä¸š"]):
        return "business_analysis_path"
    
    # æŠ€æœ¯è°ƒç ”è·¯å¾„
    elif any(keyword in topic.lower() for keyword in ["æŠ€æœ¯", "å¼€å‘", "æ¶æ„", "ç®—æ³•"]):
        return "technical_research_path"
    
    # é»˜è®¤é€šç”¨è·¯å¾„
    else:
        return "general_research_path"

# æ·»åŠ æ¡ä»¶è¾¹
workflow.add_conditional_edges(
    "initialize",
    self._intelligent_routing,
    {
        "academic_research_path": "academic_search",
        "business_analysis_path": "market_analysis", 
        "technical_research_path": "technical_search",
        "general_research_path": "general_search"
    }
)
```

### 3. æ·»åŠ äººå·¥å¹²é¢„ç‚¹

#### äº¤äº’å¼ç¡®è®¤èŠ‚ç‚¹
```python
from langgraph.types import interrupt

async def _interactive_confirmation_node(self, state: StudioResearchState) -> StudioResearchState:
    """äº¤äº’å¼ç¡®è®¤èŠ‚ç‚¹"""
    
    # åœ¨ Studio ä¸­è§¦å‘äººå·¥å¹²é¢„
    user_decision = interrupt(
        {
            "message": "è¯·ç¡®è®¤ç ”ç©¶å¤§çº²æ˜¯å¦æ»¡è¶³éœ€æ±‚",
            "outline": state["outline"],
            "options": {
                "approve": "æ‰¹å‡†å¹¶ç»§ç»­",
                "modify": "éœ€è¦ä¿®æ”¹", 
                "regenerate": "é‡æ–°ç”Ÿæˆ"
            }
        }
    )
    
    # è®°å½•ç”¨æˆ·å¹²é¢„
    interventions = state.get("user_interventions", [])
    interventions.append({
        "timestamp": asyncio.get_event_loop().time(),
        "node": "interactive_confirmation",
        "decision": user_decision
    })
    
    return {
        **state,
        "outline_approved": user_decision.get("approve", False),
        "outline_feedback": user_decision.get("feedback"),
        "user_interventions": interventions
    }
```

## ğŸ® ä½¿ç”¨ Studio è°ƒè¯•åŠŸèƒ½

### 1. æ–­ç‚¹è°ƒè¯•

#### è®¾ç½®æ–­ç‚¹
```python
async def _debug_enabled_node(self, state: StudioResearchState) -> StudioResearchState:
    """æ”¯æŒæ–­ç‚¹çš„èŠ‚ç‚¹"""
    
    # åœ¨ Studio ä¸­è®¾ç½®æ–­ç‚¹
    if state.get("debug_mode"):
        # Studio ä¼šåœ¨è¿™é‡Œæš‚åœæ‰§è¡Œ
        breakpoint_info = {
            "node": "debug_enabled_node",
            "state_keys": list(state.keys()),
            "current_topic": state.get("topic"),
            "execution_stage": state.get("stage")
        }
        
        # åœ¨ Studio ç•Œé¢ä¸­æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
        print(f"[Studio Breakpoint] {breakpoint_info}")
    
    # ç»§ç»­æ‰§è¡ŒèŠ‚ç‚¹é€»è¾‘
    return await self._execute_node_logic(state)
```

#### å•æ­¥æ‰§è¡Œ
```python
# åœ¨ Studio ä¸­å¯ç”¨å•æ­¥æ¨¡å¼
config = {
    "configurable": {
        "thread_id": "debug-session-001",
        "debug_mode": True,
        "step_by_step": True
    }
}

# æ‰§è¡Œå·¥ä½œæµ
result = await app.astream(
    {"topic": "äººå·¥æ™ºèƒ½å‘å±•è¶‹åŠ¿", "research_depth": "advanced"},
    config=config
)
```

### 2. çŠ¶æ€æ£€æŸ¥å’Œä¿®æ”¹

#### å®æ—¶çŠ¶æ€ç›‘æ§
```python
def get_detailed_state_info(state: StudioResearchState) -> Dict[str, Any]:
    """è·å–è¯¦ç»†çš„çŠ¶æ€ä¿¡æ¯"""
    
    return {
        "basic_info": {
            "topic": state.get("topic"),
            "stage": state.get("stage"), 
            "progress": f"{state.get('current_section', 0)}/{len(state.get('outline', {}).get('sections', []))}"
        },
        "performance": {
            "execution_time": state.get("performance_metrics", {}).get("execution_time"),
            "memory_usage": state.get("performance_metrics", {}).get("memory_usage"),
            "api_calls": state.get("performance_metrics", {}).get("api_calls")
        },
        "debugging": {
            "last_error": state.get("error_message"),
            "intervention_count": len(state.get("user_interventions", [])),
            "debug_flags": state.get("debug_info", {})
        }
    }
```

#### æ‰‹åŠ¨çŠ¶æ€ä¿®æ”¹
```python
# åœ¨ Studio ä¸­æ‰‹åŠ¨ä¿®æ”¹çŠ¶æ€
def modify_state_in_studio(graph, config, updates):
    """åœ¨ Studio ä¸­ä¿®æ”¹çŠ¶æ€"""
    
    # è·å–å½“å‰çŠ¶æ€
    current_state = graph.get_state(config)
    
    # åº”ç”¨ä¿®æ”¹
    graph.update_state(config, updates)
    
    # éªŒè¯ä¿®æ”¹
    new_state = graph.get_state(config)
    
    return {
        "before": current_state.values,
        "after": new_state.values,
        "changes": updates
    }

# ä½¿ç”¨ç¤ºä¾‹
updates = {
    "research_depth": "advanced",
    "outline_approved": True,
    "debug_info": {"manual_override": True}
}

modify_state_in_studio(app, config, updates)
```

### 3. æ€§èƒ½åˆ†æ

#### èŠ‚ç‚¹æ‰§è¡Œæ—¶é—´è·Ÿè¸ª
```python
import time
from functools import wraps

def track_execution_time(func):
    """è·Ÿè¸ªèŠ‚ç‚¹æ‰§è¡Œæ—¶é—´çš„è£…é¥°å™¨"""
    
    @wraps(func)
    async def wrapper(self, state: StudioResearchState):
        start_time = time.time()
        
        try:
            result = await func(self, state)
            execution_time = time.time() - start_time
            
            # æ›´æ–°æ€§èƒ½æŒ‡æ ‡
            metrics = result.get("performance_metrics", {})
            node_times = metrics.get("node_execution_times", {})
            node_times[func.__name__] = execution_time
            
            result["performance_metrics"] = {
                **metrics,
                "node_execution_times": node_times,
                "total_execution_time": metrics.get("total_execution_time", 0) + execution_time
            }
            
            return result
            
        except Exception as e:
            execution_time = time.time() - start_time
            print(f"[Studio Error] {func.__name__} æ‰§è¡Œå¤±è´¥: {e} (è€—æ—¶: {execution_time:.2f}s)")
            raise
    
    return wrapper

# åº”ç”¨åˆ°èŠ‚ç‚¹
@track_execution_time
async def _tracked_outline_node(self, state: StudioResearchState) -> StudioResearchState:
    """è·Ÿè¸ªæ‰§è¡Œæ—¶é—´çš„å¤§çº²èŠ‚ç‚¹"""
    return await self._generate_outline_logic(state)
```

## ğŸ“Š åˆ›å»ºè‡ªå®šä¹‰ä»ªè¡¨æ¿

### 1. ç ”ç©¶è¿›åº¦å¯è§†åŒ–

```python
def create_progress_dashboard(state: StudioResearchState) -> Dict[str, Any]:
    """åˆ›å»ºç ”ç©¶è¿›åº¦ä»ªè¡¨æ¿"""
    
    outline = state.get("outline", {})
    sections = outline.get("sections", [])
    
    # è®¡ç®—è¿›åº¦
    total_sections = len(sections)
    completed_sections = state.get("current_section", 0)
    progress_percentage = (completed_sections / total_sections * 100) if total_sections > 0 else 0
    
    # æ€§èƒ½æŒ‡æ ‡
    metrics = state.get("performance_metrics", {})
    
    return {
        "progress": {
            "percentage": progress_percentage,
            "completed_sections": completed_sections,
            "total_sections": total_sections,
            "current_stage": state.get("stage")
        },
        "performance": {
            "total_time": metrics.get("total_execution_time", 0),
            "avg_node_time": metrics.get("avg_node_execution_time", 0),
            "api_calls": metrics.get("api_calls", 0)
        },
        "quality": {
            "user_interventions": len(state.get("user_interventions", [])),
            "error_count": len([i for i in state.get("user_interventions", []) if i.get("type") == "error"]),
            "approval_rate": state.get("approval_rate", 0)
        }
    }
```

### 2. å®æ—¶ç›‘æ§ç»„ä»¶

```python
class StudioMonitor:
    """Studio å®æ—¶ç›‘æ§ç»„ä»¶"""
    
    def __init__(self, graph, config):
        self.graph = graph
        self.config = config
        self.metrics_history = []
    
    async def start_monitoring(self):
        """å¼€å§‹å®æ—¶ç›‘æ§"""
        
        while True:
            try:
                # è·å–å½“å‰çŠ¶æ€
                current_state = self.graph.get_state(self.config)
                
                # ç”Ÿæˆç›‘æ§æ•°æ®
                monitoring_data = {
                    "timestamp": time.time(),
                    "state_summary": self._summarize_state(current_state.values),
                    "performance": self._calculate_performance_metrics(current_state.values),
                    "health": self._check_system_health(current_state.values)
                }
                
                self.metrics_history.append(monitoring_data)
                
                # åœ¨ Studio ä¸­æ˜¾ç¤º
                print(f"[Studio Monitor] {monitoring_data}")
                
                await asyncio.sleep(1)  # æ¯ç§’æ›´æ–°ä¸€æ¬¡
                
            except Exception as e:
                print(f"[Studio Monitor Error] {e}")
                await asyncio.sleep(5)
    
    def _summarize_state(self, state: StudioResearchState) -> Dict[str, Any]:
        """æ€»ç»“å½“å‰çŠ¶æ€"""
        return {
            "stage": state.get("stage"),
            "topic": state.get("topic"),
            "progress": f"{state.get('current_section', 0)}/{len(state.get('outline', {}).get('sections', []))}"
        }
```

## ğŸš€ é«˜çº§è‡ªå®šä¹‰åŠŸèƒ½

### 1. è‡ªå®šä¹‰ç ”ç©¶æ¨¡æ¿

#### å­¦æœ¯ç ”ç©¶æ¨¡æ¿
```python
class AcademicResearchTemplate:
    """å­¦æœ¯ç ”ç©¶æ¨¡æ¿"""
    
    @staticmethod
    def get_workflow_config() -> Dict[str, Any]:
        return {
            "name": "academic_research",
            "description": "ä¸“é—¨ç”¨äºå­¦æœ¯ç ”ç©¶çš„å·¥ä½œæµæ¨¡æ¿",
            "nodes": [
                "initialize",
                "literature_review",
                "hypothesis_generation", 
                "methodology_design",
                "data_collection",
                "analysis",
                "conclusion_writing",
                "peer_review"
            ],
            "default_settings": {
                "research_depth": "advanced",
                "citation_style": "APA",
                "peer_review_required": True,
                "search_engines": ["arxiv", "google_scholar", "pubmed"]
            }
        }
    
    @staticmethod
    def build_workflow() -> StateGraph:
        """æ„å»ºå­¦æœ¯ç ”ç©¶å·¥ä½œæµ"""
        
        workflow = StateGraph(StudioResearchState)
        
        # å­¦æœ¯ç ”ç©¶ç‰¹æœ‰çš„èŠ‚ç‚¹
        workflow.add_node("literature_review", AcademicResearchTemplate._literature_review_node)
        workflow.add_node("hypothesis_generation", AcademicResearchTemplate._hypothesis_node)
        workflow.add_node("methodology_design", AcademicResearchTemplate._methodology_node)
        workflow.add_node("peer_review", AcademicResearchTemplate._peer_review_node)
        
        # å­¦æœ¯ç ”ç©¶æµç¨‹
        workflow.set_entry_point("initialize")
        workflow.add_edge("initialize", "literature_review")
        workflow.add_edge("literature_review", "hypothesis_generation")
        workflow.add_edge("hypothesis_generation", "methodology_design")
        workflow.add_edge("methodology_design", "data_collection")
        workflow.add_edge("data_collection", "analysis")
        workflow.add_edge("analysis", "conclusion_writing")
        workflow.add_edge("conclusion_writing", "peer_review")
        workflow.add_edge("peer_review", END)
        
        return workflow
```

#### å•†ä¸šåˆ†ææ¨¡æ¿
```python
class BusinessAnalysisTemplate:
    """å•†ä¸šåˆ†ææ¨¡æ¿"""
    
    @staticmethod
    def get_workflow_config() -> Dict[str, Any]:
        return {
            "name": "business_analysis",
            "description": "ä¸“é—¨ç”¨äºå•†ä¸šåˆ†æçš„å·¥ä½œæµæ¨¡æ¿",
            "nodes": [
                "market_research",
                "competitor_analysis",
                "swot_analysis",
                "financial_modeling",
                "recommendation_generation"
            ],
            "default_settings": {
                "analysis_frameworks": ["Porter's Five Forces", "SWOT", "PESTEL"],
                "data_sources": ["company_reports", "market_data", "news"],
                "output_format": "executive_summary"
            }
        }
```

### 2. æ’ä»¶ç³»ç»Ÿ

#### è‡ªå®šä¹‰æ’ä»¶æ¥å£
```python
from abc import ABC, abstractmethod

class StudioPlugin(ABC):
    """Studio æ’ä»¶åŸºç±»"""
    
    @abstractmethod
    def get_name(self) -> str:
        """è·å–æ’ä»¶åç§°"""
        pass
    
    @abstractmethod
    def get_nodes(self) -> Dict[str, callable]:
        """è·å–æ’ä»¶æä¾›çš„èŠ‚ç‚¹"""
        pass
    
    @abstractmethod
    def get_tools(self) -> List[Any]:
        """è·å–æ’ä»¶æä¾›çš„å·¥å…·"""
        pass

class AdvancedAnalyticsPlugin(StudioPlugin):
    """é«˜çº§åˆ†ææ’ä»¶"""
    
    def get_name(self) -> str:
        return "advanced_analytics"
    
    def get_nodes(self) -> Dict[str, callable]:
        return {
            "sentiment_analysis": self._sentiment_analysis_node,
            "trend_prediction": self._trend_prediction_node,
            "topic_modeling": self._topic_modeling_node
        }
    
    def get_tools(self) -> List[Any]:
        return [
            SentimentAnalysisTool(),
            TrendPredictionTool(),
            TopicModelingTool()
        ]
    
    async def _sentiment_analysis_node(self, state: StudioResearchState) -> StudioResearchState:
        """æƒ…æ„Ÿåˆ†æèŠ‚ç‚¹"""
        # å®ç°æƒ…æ„Ÿåˆ†æé€»è¾‘
        pass
```

### 3. è‡ªåŠ¨åŒ–æµ‹è¯•

#### å·¥ä½œæµæµ‹è¯•æ¡†æ¶
```python
import pytest
from unittest.mock import AsyncMock

class WorkflowTestFramework:
    """å·¥ä½œæµæµ‹è¯•æ¡†æ¶"""
    
    def __init__(self, workflow_class):
        self.workflow_class = workflow_class
    
    async def test_node_execution(self, node_name: str, test_state: StudioResearchState):
        """æµ‹è¯•å•ä¸ªèŠ‚ç‚¹çš„æ‰§è¡Œ"""
        
        workflow = self.workflow_class()
        node_func = getattr(workflow, f"_{node_name}_node")
        
        # æ‰§è¡ŒèŠ‚ç‚¹
        result = await node_func(test_state)
        
        # éªŒè¯ç»“æœ
        assert result is not None
        assert isinstance(result, dict)
        
        return result
    
    async def test_full_workflow(self, initial_state: StudioResearchState):
        """æµ‹è¯•å®Œæ•´å·¥ä½œæµ"""
        
        workflow = self.workflow_class()
        
        config = {"configurable": {"thread_id": "test-001"}}
        
        # æ‰§è¡Œå·¥ä½œæµ
        result = await workflow.graph.ainvoke(initial_state, config=config)
        
        # éªŒè¯æœ€ç»ˆç»“æœ
        assert result.get("stage") == "complete"
        assert "error_message" not in result or result["error_message"] is None
        
        return result

# ä½¿ç”¨ç¤ºä¾‹
@pytest.mark.asyncio
async def test_research_workflow():
    """æµ‹è¯•ç ”ç©¶å·¥ä½œæµ"""
    
    test_framework = WorkflowTestFramework(StudioResearchWorkflow)
    
    initial_state = {
        "topic": "æµ‹è¯•ä¸»é¢˜",
        "research_depth": "basic", 
        "language": "zh-CN"
    }
    
    result = await test_framework.test_full_workflow(initial_state)
    assert result["topic"] == "æµ‹è¯•ä¸»é¢˜"
```

## ğŸ“š æœ€ä½³å®è·µ

### 1. æ€§èƒ½ä¼˜åŒ–

#### å¼‚æ­¥æ‰§è¡Œä¼˜åŒ–
```python
import asyncio
from concurrent.futures import ThreadPoolExecutor

class OptimizedWorkflow(StudioResearchWorkflow):
    """æ€§èƒ½ä¼˜åŒ–çš„å·¥ä½œæµ"""
    
    def __init__(self):
        super().__init__()
        self.executor = ThreadPoolExecutor(max_workers=4)
    
    async def _parallel_search_node(self, state: StudioResearchState) -> StudioResearchState:
        """å¹¶è¡Œæœç´¢èŠ‚ç‚¹"""
        
        search_tasks = []
        search_engines = ["tavily", "arxiv", "duckduckgo"]
        
        # å¹¶è¡Œæ‰§è¡Œå¤šä¸ªæœç´¢
        for engine in search_engines:
            task = asyncio.create_task(
                self._search_with_engine(state["topic"], engine)
            )
            search_tasks.append(task)
        
        # ç­‰å¾…æ‰€æœ‰æœç´¢å®Œæˆ
        search_results = await asyncio.gather(*search_tasks, return_exceptions=True)
        
        # åˆå¹¶ç»“æœ
        combined_results = []
        for result in search_results:
            if not isinstance(result, Exception):
                combined_results.extend(result)
        
        return {
            **state,
            "search_results": combined_results,
            "performance_metrics": {
                **state.get("performance_metrics", {}),
                "parallel_searches": len(search_engines)
            }
        }
```

#### ç¼“å­˜ä¼˜åŒ–
```python
from functools import lru_cache
import hashlib

class CachedWorkflow(StudioResearchWorkflow):
    """å¸¦ç¼“å­˜çš„å·¥ä½œæµ"""
    
    def __init__(self):
        super().__init__()
        self.cache = {}
    
    def _get_cache_key(self, *args) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        content = str(args)
        return hashlib.md5(content.encode()).hexdigest()
    
    async def _cached_llm_call(self, prompt: str, **kwargs) -> str:
        """å¸¦ç¼“å­˜çš„ LLM è°ƒç”¨"""
        
        cache_key = self._get_cache_key(prompt, kwargs)
        
        if cache_key in self.cache:
            print(f"[Studio Cache] ç¼“å­˜å‘½ä¸­: {cache_key[:8]}...")
            return self.cache[cache_key]
        
        # æ‰§è¡Œ LLM è°ƒç”¨
        result = await self.llm.generate(prompt, **kwargs)
        
        # ç¼“å­˜ç»“æœ
        self.cache[cache_key] = result.content
        
        return result.content
```

### 2. é”™è¯¯å¤„ç†

#### å¥å£®çš„é”™è¯¯å¤„ç†
```python
import traceback
from typing import Union

class RobustWorkflow(StudioResearchWorkflow):
    """å¥å£®çš„å·¥ä½œæµå®ç°"""
    
    async def _safe_node_execution(self, node_func, state: StudioResearchState) -> StudioResearchState:
        """å®‰å…¨çš„èŠ‚ç‚¹æ‰§è¡Œ"""
        
        try:
            result = await node_func(state)
            
            # éªŒè¯ç»“æœ
            if not isinstance(result, dict):
                raise ValueError(f"èŠ‚ç‚¹è¿”å›äº†æ— æ•ˆçš„ç»“æœç±»å‹: {type(result)}")
            
            return result
            
        except Exception as e:
            error_info = {
                "error_type": type(e).__name__,
                "error_message": str(e),
                "traceback": traceback.format_exc(),
                "node": node_func.__name__,
                "timestamp": asyncio.get_event_loop().time()
            }
            
            print(f"[Studio Error] èŠ‚ç‚¹æ‰§è¡Œå¤±è´¥: {error_info}")
            
            return {
                **state,
                "error_message": str(e),
                "error_details": error_info,
                "stage": "error"
            }
    
    async def _error_recovery_node(self, state: StudioResearchState) -> StudioResearchState:
        """é”™è¯¯æ¢å¤èŠ‚ç‚¹"""
        
        error_details = state.get("error_details", {})
        error_type = error_details.get("error_type")
        
        # æ ¹æ®é”™è¯¯ç±»å‹æ‰§è¡Œä¸åŒçš„æ¢å¤ç­–ç•¥
        if error_type == "APIError":
            return await self._handle_api_error(state)
        elif error_type == "ValidationError":
            return await self._handle_validation_error(state)
        else:
            return await self._handle_generic_error(state)
```

### 3. ç›‘æ§å’Œæ—¥å¿—

#### è¯¦ç»†çš„ç›‘æ§ç³»ç»Ÿ
```python
import logging
from datetime import datetime

class MonitoredWorkflow(StudioResearchWorkflow):
    """å¸¦ç›‘æ§çš„å·¥ä½œæµ"""
    
    def __init__(self):
        super().__init__()
        self.setup_logging()
        self.metrics_collector = MetricsCollector()
    
    def setup_logging(self):
        """è®¾ç½®è¯¦ç»†çš„æ—¥å¿—è®°å½•"""
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('studio_workflow.log'),
                logging.StreamHandler()
            ]
        )
        
        self.logger = logging.getLogger("StudioWorkflow")
    
    async def _monitored_node_execution(self, node_name: str, node_func, state: StudioResearchState):
        """å¸¦ç›‘æ§çš„èŠ‚ç‚¹æ‰§è¡Œ"""
        
        start_time = datetime.now()
        self.logger.info(f"å¼€å§‹æ‰§è¡ŒèŠ‚ç‚¹: {node_name}")
        
        try:
            result = await node_func(state)
            
            execution_time = (datetime.now() - start_time).total_seconds()
            
            # è®°å½•æˆåŠŸæ‰§è¡Œ
            self.logger.info(f"èŠ‚ç‚¹ {node_name} æ‰§è¡ŒæˆåŠŸï¼Œè€—æ—¶: {execution_time:.2f}s")
            self.metrics_collector.record_success(node_name, execution_time)
            
            return result
            
        except Exception as e:
            execution_time = (datetime.now() - start_time).total_seconds()
            
            # è®°å½•æ‰§è¡Œå¤±è´¥
            self.logger.error(f"èŠ‚ç‚¹ {node_name} æ‰§è¡Œå¤±è´¥ï¼Œè€—æ—¶: {execution_time:.2f}sï¼Œé”™è¯¯: {e}")
            self.metrics_collector.record_failure(node_name, execution_time, str(e))
            
            raise

class MetricsCollector:
    """æŒ‡æ ‡æ”¶é›†å™¨"""
    
    def __init__(self):
        self.success_metrics = {}
        self.failure_metrics = {}
    
    def record_success(self, node_name: str, execution_time: float):
        """è®°å½•æˆåŠŸæ‰§è¡Œ"""
        if node_name not in self.success_metrics:
            self.success_metrics[node_name] = []
        
        self.success_metrics[node_name].append({
            "timestamp": datetime.now(),
            "execution_time": execution_time
        })
    
    def record_failure(self, node_name: str, execution_time: float, error: str):
        """è®°å½•æ‰§è¡Œå¤±è´¥"""
        if node_name not in self.failure_metrics:
            self.failure_metrics[node_name] = []
        
        self.failure_metrics[node_name].append({
            "timestamp": datetime.now(),
            "execution_time": execution_time,
            "error": error
        })
    
    def get_performance_report(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æŠ¥å‘Š"""
        
        report = {}
        
        for node_name, metrics in self.success_metrics.items():
            execution_times = [m["execution_time"] for m in metrics]
            
            report[node_name] = {
                "success_count": len(metrics),
                "avg_execution_time": sum(execution_times) / len(execution_times),
                "min_execution_time": min(execution_times),
                "max_execution_time": max(execution_times),
                "failure_count": len(self.failure_metrics.get(node_name, []))
            }
        
        return report
```

## ğŸ“ è¿›é˜¶æ•™ç¨‹

### 1. åˆ›å»ºè‡ªå®šä¹‰å¯è§†åŒ–

#### è‡ªå®šä¹‰èŠ‚ç‚¹æ ·å¼
```python
def get_node_style_config() -> Dict[str, Any]:
    """è·å–è‡ªå®šä¹‰èŠ‚ç‚¹æ ·å¼é…ç½®"""
    
    return {
        "node_styles": {
            "initialize": {
                "color": "#4CAF50",
                "shape": "circle",
                "icon": "ğŸš€"
            },
            "generate_outline": {
                "color": "#2196F3", 
                "shape": "rectangle",
                "icon": "ğŸ“‹"
            },
            "search_information": {
                "color": "#FF9800",
                "shape": "diamond", 
                "icon": "ğŸ”"
            },
            "generate_content": {
                "color": "#9C27B0",
                "shape": "rectangle",
                "icon": "âœï¸"
            },
            "finalize_report": {
                "color": "#4CAF50",
                "shape": "circle",
                "icon": "ğŸ“„"
            }
        },
        "edge_styles": {
            "normal": {"color": "#666", "width": 2},
            "conditional": {"color": "#FF5722", "width": 3, "style": "dashed"},
            "error": {"color": "#F44336", "width": 2, "style": "dotted"}
        }
    }
```

### 2. é›†æˆå¤–éƒ¨å·¥å…·

#### æ•°æ®åº“é›†æˆ
```python
import asyncpg
from typing import Optional

class DatabaseIntegratedWorkflow(StudioResearchWorkflow):
    """é›†æˆæ•°æ®åº“çš„å·¥ä½œæµ"""
    
    def __init__(self, db_url: str):
        super().__init__()
        self.db_url = db_url
        self.db_pool: Optional[asyncpg.Pool] = None
    
    async def _initialize_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¿æ¥"""
        self.db_pool = await asyncpg.create_pool(self.db_url)
    
    async def _save_research_state(self, state: StudioResearchState) -> StudioResearchState:
        """ä¿å­˜ç ”ç©¶çŠ¶æ€åˆ°æ•°æ®åº“"""
        
        if not self.db_pool:
            await self._initialize_database()
        
        async with self.db_pool.acquire() as conn:
            await conn.execute("""
                INSERT INTO research_sessions (
                    topic, stage, outline, content_map, created_at
                ) VALUES ($1, $2, $3, $4, NOW())
            """, 
            state["topic"],
            state["stage"], 
            json.dumps(state.get("outline")),
            json.dumps(state.get("content_map"))
            )
        
        return state
    
    async def _load_research_history(self, topic: str) -> List[Dict[str, Any]]:
        """åŠ è½½ç ”ç©¶å†å²"""
        
        async with self.db_pool.acquire() as conn:
            rows = await conn.fetch("""
                SELECT * FROM research_sessions 
                WHERE topic = $1 
                ORDER BY created_at DESC
            """, topic)
            
            return [dict(row) for row in rows]
```

## ğŸ“– æ€»ç»“

LangGraph Studio ä¸º DeepResearch æä¾›äº†å¼ºå¤§çš„å¯è§†åŒ–å’Œè°ƒè¯•åŠŸèƒ½ï¼Œé€šè¿‡æœ¬æŒ‡å—æ‚¨åº”è¯¥å·²ç»æŒæ¡äº†ï¼š

### âœ… æ ¸å¿ƒæŠ€èƒ½
- ğŸ—ï¸ å·¥ä½œæµå¯è§†åŒ–å’Œè°ƒè¯•
- ğŸ”§ è‡ªå®šä¹‰èŠ‚ç‚¹å’Œæ¡ä»¶åˆ†æ”¯
- ğŸ® äº¤äº’å¼è°ƒè¯•æŠ€æœ¯
- ğŸ“Š çŠ¶æ€ç®¡ç†å’Œç›‘æ§
- ğŸš€ æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

### ğŸ”„ ä¸‹ä¸€æ­¥
1. **å®è·µç»ƒä¹ ** - ä½¿ç”¨ Studio ä¿®æ”¹ç°æœ‰çš„ç ”ç©¶å·¥ä½œæµ
2. **åˆ›å»ºæ¨¡æ¿** - ä¸ºç‰¹å®šç ”ç©¶é¢†åŸŸåˆ›å»ºä¸“ç”¨æ¨¡æ¿
3. **æ’ä»¶å¼€å‘** - å¼€å‘è‡ªå®šä¹‰æ’ä»¶æ‰©å±•åŠŸèƒ½
4. **å›¢é˜Ÿåä½œ** - ä¸å›¢é˜Ÿæˆå‘˜å…±äº«å’Œåä½œå·¥ä½œæµ

### ğŸ“š ç›¸å…³èµ„æº
- [LangGraph å®˜æ–¹æ–‡æ¡£](https://langchain-ai.github.io/langgraph/)
- [LangGraph Studio ä¸‹è½½](https://github.com/langchain-ai/langgraph-studio)
- [LangSmith å¹³å°](https://smith.langchain.com/)
- [DeepResearch å·¥ä½œæµæ–‡æ¡£](./tools.md)

---

**é€šè¿‡ LangGraph Studioï¼Œè®©æ‚¨çš„ç ”ç©¶å·¥ä½œæµå¼€å‘æ›´åŠ ç›´è§‚ã€é«˜æ•ˆå’Œå¼ºå¤§ï¼** ğŸ¨âœ¨ 