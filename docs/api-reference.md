# DeepResearch API å‚è€ƒæ–‡æ¡£

## ğŸ“‹ API æ¦‚è§ˆ

DeepResearch æä¾›å®Œæ•´çš„ REST API å’Œ Python SDKï¼Œæ”¯æŒç¨‹åºåŒ–è®¿é—®æ‰€æœ‰åŠŸèƒ½ã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

### Python SDK

```python
from deepresearch import DeepResearchClient

# åˆå§‹åŒ–å®¢æˆ·ç«¯
client = DeepResearchClient(
    api_key="your-api-key",
    base_url="http://localhost:8000"
)

# åˆ›å»ºç ”ç©¶ä»»åŠ¡
research = client.research.create(
    topic="äººå·¥æ™ºèƒ½å‘å±•è¶‹åŠ¿",
    mode="interactive",
    provider="openai"
)

# è·å–ç»“æœ
result = client.research.get(research.id)
print(result.content)
```

### REST API

```bash
# åˆ›å»ºç ”ç©¶ä»»åŠ¡
curl -X POST "http://localhost:8000/api/v1/research" \
  -H "Authorization: Bearer your-api-key" \
  -H "Content-Type: application/json" \
  -d '{
    "topic": "äººå·¥æ™ºèƒ½å‘å±•è¶‹åŠ¿",
    "mode": "auto",
    "provider": "openai",
    "max_sections": 5
  }'
```

## ğŸ”§ æ ¸å¿ƒ API

### ç ”ç©¶ API

#### åˆ›å»ºç ”ç©¶ä»»åŠ¡

**POST** `/api/v1/research`

```json
{
  "topic": "ç ”ç©¶ä¸»é¢˜",
  "mode": "interactive|auto",
  "provider": "openai|claude|gemini|ollama",
  "max_sections": 5,
  "template": "default|academic|business",
  "language": "zh-CN|en-US",
  "output_format": "markdown|json|pdf"
}
```

**å“åº”ï¼š**
```json
{
  "id": "research_123456",
  "status": "created",
  "topic": "ç ”ç©¶ä¸»é¢˜",
  "created_at": "2024-01-01T00:00:00Z",
  "estimated_duration": 300
}
```

#### è·å–ç ”ç©¶çŠ¶æ€

**GET** `/api/v1/research/{research_id}`

**å“åº”ï¼š**
```json
{
  "id": "research_123456",
  "status": "processing|completed|failed",
  "progress": 75,
  "current_step": "content_generation",
  "estimated_remaining": 60,
  "result_url": "/api/v1/research/research_123456/result"
}
```

#### è·å–ç ”ç©¶ç»“æœ

**GET** `/api/v1/research/{research_id}/result`

**å“åº”ï¼š**
```json
{
  "id": "research_123456",
  "topic": "ç ”ç©¶ä¸»é¢˜",
  "content": "# ç ”ç©¶æŠ¥å‘Š\n\n...",
  "outline": {
    "sections": [...]
  },
  "metadata": {
    "word_count": 5000,
    "generation_time": 180,
    "quality_score": 0.85
  },
  "references": [...]
}
```

#### æµå¼è·å–ç ”ç©¶è¿›åº¦

**WebSocket** `/api/v1/research/{research_id}/stream`

```javascript
const ws = new WebSocket('ws://localhost:8000/api/v1/research/123456/stream');

ws.onmessage = function(event) {
  const data = JSON.parse(event.data);
  console.log('Progress:', data.progress);
  console.log('Current step:', data.current_step);
};
```

### é…ç½® API

#### è·å–ç³»ç»Ÿé…ç½®

**GET** `/api/v1/config`

**å“åº”ï¼š**
```json
{
  "llm_providers": ["openai", "claude", "gemini"],
  "search_engines": ["google", "bing", "serpapi"],
  "supported_languages": ["zh-CN", "en-US"],
  "max_concurrent_requests": 5,
  "default_provider": "openai"
}
```

#### éªŒè¯ API å¯†é’¥

**POST** `/api/v1/config/validate`

```json
{
  "provider": "openai",
  "api_key": "sk-..."
}
```

**å“åº”ï¼š**
```json
{
  "valid": true,
  "provider": "openai",
  "model_access": ["gpt-4", "gpt-3.5-turbo"],
  "quota_remaining": 1000000
}
```

### å·¥å…· API

#### æ‰§è¡Œä»£ç 

**POST** `/api/v1/tools/code/execute`

```json
{
  "code": "import pandas as pd\nprint('Hello World')",
  "language": "python",
  "timeout": 30
}
```

**å“åº”ï¼š**
```json
{
  "success": true,
  "output": "Hello World\n",
  "execution_time": 0.5,
  "memory_usage": 1024
}
```

#### æœç´¢ä¿¡æ¯

**POST** `/api/v1/tools/search`

```json
{
  "query": "äººå·¥æ™ºèƒ½å‘å±•è¶‹åŠ¿",
  "engine": "google",
  "max_results": 10
}
```

**å“åº”ï¼š**
```json
{
  "results": [
    {
      "title": "æ ‡é¢˜",
      "url": "https://example.com",
      "snippet": "æ‘˜è¦",
      "relevance_score": 0.95
    }
  ],
  "total_results": 10,
  "search_time": 1.2
}
```

#### æµè§ˆç½‘é¡µ

**POST** `/api/v1/tools/browser/extract`

```json
{
  "url": "https://example.com",
  "extract_text": true,
  "extract_images": false,
  "wait_for": "body"
}
```

**å“åº”ï¼š**
```json
{
  "success": true,
  "content": "ç½‘é¡µæ–‡æœ¬å†…å®¹",
  "title": "ç½‘é¡µæ ‡é¢˜",
  "meta": {
    "description": "ç½‘é¡µæè¿°",
    "keywords": ["å…³é”®è¯1", "å…³é”®è¯2"]
  }
}
```

## ğŸ Python SDK

### å®‰è£…

```bash
pip install deepresearch-sdk
```

### åŸºæœ¬ä½¿ç”¨

```python
from deepresearch import DeepResearchClient

# åˆå§‹åŒ–å®¢æˆ·ç«¯
client = DeepResearchClient(
    api_key="your-api-key",
    base_url="http://localhost:8000"
)

# åŒæ­¥ç ”ç©¶
result = client.research.create_and_wait(
    topic="äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨",
    provider="claude",
    max_sections=6
)

print(result.content)
```

### å¼‚æ­¥ä½¿ç”¨

```python
import asyncio
from deepresearch import AsyncDeepResearchClient

async def main():
    client = AsyncDeepResearchClient(
        api_key="your-api-key",
        base_url="http://localhost:8000"
    )
    
    # åˆ›å»ºç ”ç©¶ä»»åŠ¡
    research = await client.research.create(
        topic="åŒºå—é“¾æŠ€æœ¯å‘å±•è¶‹åŠ¿",
        mode="auto"
    )
    
    # ç›‘å¬è¿›åº¦
    async for progress in client.research.stream_progress(research.id):
        print(f"è¿›åº¦: {progress.percentage}%")
        print(f"å½“å‰æ­¥éª¤: {progress.current_step}")
    
    # è·å–ç»“æœ
    result = await client.research.get_result(research.id)
    return result

result = asyncio.run(main())
```

### æ‰¹é‡å¤„ç†

```python
from deepresearch import DeepResearchClient

client = DeepResearchClient(api_key="your-api-key")

# æ‰¹é‡åˆ›å»ºç ”ç©¶ä»»åŠ¡
topics = [
    "äººå·¥æ™ºèƒ½ä¼¦ç†é—®é¢˜",
    "é‡å­è®¡ç®—å•†ä¸šåº”ç”¨",
    "å¯æŒç»­èƒ½æºæŠ€æœ¯"
]

# å¹¶è¡Œå¤„ç†
research_tasks = []
for topic in topics:
    task = client.research.create(topic=topic, mode="auto")
    research_tasks.append(task)

# ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
results = client.research.wait_for_completion(research_tasks)

for result in results:
    print(f"ä¸»é¢˜: {result.topic}")
    print(f"çŠ¶æ€: {result.status}")
    print(f"å†…å®¹é•¿åº¦: {len(result.content)}")
```

## ğŸ”§ å·¥å…· SDK

### ä»£ç æ‰§è¡Œå·¥å…·

```python
from deepresearch.tools import CodeTool

code_tool = CodeTool(client)

# æ‰§è¡Œ Python ä»£ç 
result = code_tool.execute("""
import matplotlib.pyplot as plt
import numpy as np

x = np.linspace(0, 10, 100)
y = np.sin(x)

plt.figure(figsize=(10, 6))
plt.plot(x, y)
plt.title('æ­£å¼¦å‡½æ•°')
plt.savefig('sin_wave.png')
plt.show()
""")

print(result.output)
print(f"æ‰§è¡Œæ—¶é—´: {result.execution_time}s")
```

### æœç´¢å·¥å…·

```python
from deepresearch.tools import SearchTool

search_tool = SearchTool(client)

# å¤šå¼•æ“æœç´¢
results = search_tool.search(
    query="äººå·¥æ™ºèƒ½å‘å±•è¶‹åŠ¿",
    engines=["google", "bing"],
    max_results=20
)

for result in results:
    print(f"æ ‡é¢˜: {result.title}")
    print(f"URL: {result.url}")
    print(f"ç›¸å…³æ€§: {result.relevance_score}")
```

### æµè§ˆå™¨å·¥å…·

```python
from deepresearch.tools import BrowserTool

browser_tool = BrowserTool(client)

# æå–ç½‘é¡µå†…å®¹
content = browser_tool.extract_content(
    url="https://example.com",
    wait_for="body",
    extract_images=True
)

print(content.text)
print(f"å›¾ç‰‡æ•°é‡: {len(content.images)}")
```

## ğŸ“Š ç›‘æ§å’Œåˆ†æ API

### è·å–ç³»ç»ŸçŠ¶æ€

**GET** `/api/v1/system/status`

**å“åº”ï¼š**
```json
{
  "status": "healthy",
  "version": "2.0.0",
  "uptime": 86400,
  "active_research_tasks": 5,
  "queue_length": 2,
  "system_load": {
    "cpu": 45.2,
    "memory": 68.5,
    "disk": 23.1
  }
}
```

### è·å–ä½¿ç”¨ç»Ÿè®¡

**GET** `/api/v1/analytics/usage`

**å“åº”ï¼š**
```json
{
  "total_research_tasks": 1250,
  "completed_tasks": 1200,
  "failed_tasks": 50,
  "average_completion_time": 180,
  "api_calls_today": 5000,
  "top_providers": [
    {"provider": "openai", "usage": 60},
    {"provider": "claude", "usage": 30},
    {"provider": "gemini", "usage": 10}
  ]
}
```

### è·å–æ€§èƒ½æŒ‡æ ‡

**GET** `/api/v1/analytics/performance`

**å“åº”ï¼š**
```json
{
  "response_times": {
    "p50": 120,
    "p95": 300,
    "p99": 500
  },
  "throughput": {
    "requests_per_minute": 50,
    "tasks_per_hour": 20
  },
  "error_rates": {
    "api_errors": 0.1,
    "llm_errors": 0.5,
    "tool_errors": 0.2
  }
}
```

## ğŸ”’ è®¤è¯å’Œå®‰å…¨

### API å¯†é’¥è®¤è¯

```bash
# åœ¨è¯·æ±‚å¤´ä¸­åŒ…å« API å¯†é’¥
curl -H "Authorization: Bearer your-api-key" \
     -H "Content-Type: application/json" \
     "http://localhost:8000/api/v1/research"
```

### JWT ä»¤ç‰Œè®¤è¯

```bash
# è·å– JWT ä»¤ç‰Œ
curl -X POST "http://localhost:8000/api/v1/auth/login" \
  -H "Content-Type: application/json" \
  -d '{"username": "user", "password": "pass"}'

# ä½¿ç”¨ JWT ä»¤ç‰Œ
curl -H "Authorization: Bearer jwt-token" \
     "http://localhost:8000/api/v1/research"
```

### æƒé™æ§åˆ¶

```python
from deepresearch import DeepResearchClient

# ä½¿ç”¨å—é™æƒé™çš„å®¢æˆ·ç«¯
client = DeepResearchClient(
    api_key="limited-api-key",
    permissions=["research:read", "research:create"]
)

# æ£€æŸ¥æƒé™
if client.has_permission("research:create"):
    research = client.research.create(topic="ä¸»é¢˜")
```

## ğŸ“ é”™è¯¯å¤„ç†

### é”™è¯¯å“åº”æ ¼å¼

```json
{
  "error": {
    "code": "INVALID_API_KEY",
    "message": "æä¾›çš„ API å¯†é’¥æ— æ•ˆ",
    "details": {
      "provider": "openai",
      "suggestion": "è¯·æ£€æŸ¥ API å¯†é’¥æ ¼å¼"
    }
  },
  "request_id": "req_123456",
  "timestamp": "2024-01-01T00:00:00Z"
}
```

### å¸¸è§é”™è¯¯ä»£ç 

| é”™è¯¯ä»£ç  | HTTP çŠ¶æ€ | æè¿° |
|---------|----------|------|
| `INVALID_API_KEY` | 401 | API å¯†é’¥æ— æ•ˆ |
| `QUOTA_EXCEEDED` | 429 | é…é¢è¶…é™ |
| `INVALID_REQUEST` | 400 | è¯·æ±‚å‚æ•°æ— æ•ˆ |
| `RESOURCE_NOT_FOUND` | 404 | èµ„æºä¸å­˜åœ¨ |
| `INTERNAL_ERROR` | 500 | å†…éƒ¨æœåŠ¡å™¨é”™è¯¯ |
| `SERVICE_UNAVAILABLE` | 503 | æœåŠ¡ä¸å¯ç”¨ |

### Python SDK é”™è¯¯å¤„ç†

```python
from deepresearch import DeepResearchClient
from deepresearch.exceptions import (
    APIKeyError,
    QuotaExceededError,
    InvalidRequestError
)

client = DeepResearchClient(api_key="your-api-key")

try:
    research = client.research.create(topic="ä¸»é¢˜")
except APIKeyError:
    print("API å¯†é’¥æ— æ•ˆï¼Œè¯·æ£€æŸ¥é…ç½®")
except QuotaExceededError:
    print("é…é¢å·²ç”¨å®Œï¼Œè¯·ç¨åé‡è¯•")
except InvalidRequestError as e:
    print(f"è¯·æ±‚å‚æ•°é”™è¯¯: {e.message}")
```

## ğŸ”„ Webhooks

### é…ç½® Webhook

**POST** `/api/v1/webhooks`

```json
{
  "url": "https://your-app.com/webhook",
  "events": ["research.completed", "research.failed"],
  "secret": "webhook-secret"
}
```

### Webhook äº‹ä»¶

#### ç ”ç©¶å®Œæˆäº‹ä»¶

```json
{
  "event": "research.completed",
  "data": {
    "research_id": "research_123456",
    "topic": "ç ”ç©¶ä¸»é¢˜",
    "status": "completed",
    "result_url": "/api/v1/research/research_123456/result"
  },
  "timestamp": "2024-01-01T00:00:00Z"
}
```

#### ç ”ç©¶å¤±è´¥äº‹ä»¶

```json
{
  "event": "research.failed",
  "data": {
    "research_id": "research_123456",
    "topic": "ç ”ç©¶ä¸»é¢˜",
    "error": {
      "code": "LLM_ERROR",
      "message": "LLM æœåŠ¡ä¸å¯ç”¨"
    }
  },
  "timestamp": "2024-01-01T00:00:00Z"
}
```

## ğŸ“š ç¤ºä¾‹å’Œæ•™ç¨‹

### å®Œæ•´ç¤ºä¾‹ï¼šå­¦æœ¯ç ”ç©¶

```python
from deepresearch import DeepResearchClient

# åˆå§‹åŒ–å®¢æˆ·ç«¯
client = DeepResearchClient(api_key="your-api-key")

# åˆ›å»ºå­¦æœ¯ç ”ç©¶
research = client.research.create(
    topic="æ·±åº¦å­¦ä¹ åœ¨åŒ»å­¦å½±åƒè¯Šæ–­ä¸­çš„åº”ç”¨",
    mode="interactive",
    provider="claude",
    template="academic",
    max_sections=8,
    language="zh-CN"
)

# ç›‘å¬è¿›åº¦
for progress in client.research.stream_progress(research.id):
    print(f"è¿›åº¦: {progress.percentage}%")
    
    # å¤„ç†ç”¨æˆ·äº¤äº’
    if progress.requires_interaction:
        if progress.interaction_type == "outline_confirmation":
            # ç¡®è®¤æçº²
            client.research.confirm_outline(
                research.id,
                action="confirm"
            )

# è·å–ç»“æœ
result = client.research.get_result(research.id)

# å¯¼å‡ºä¸º PDF
pdf_data = client.research.export(
    research.id,
    format="pdf",
    template="academic"
)

with open("research_report.pdf", "wb") as f:
    f.write(pdf_data)
```

### æ‰¹é‡å•†ä¸šåˆ†æ

```python
import asyncio
from deepresearch import AsyncDeepResearchClient

async def analyze_markets():
    client = AsyncDeepResearchClient(api_key="your-api-key")
    
    markets = [
        "ç”µåŠ¨æ±½è½¦å¸‚åœºåˆ†æ",
        "äººå·¥æ™ºèƒ½èŠ¯ç‰‡å¸‚åœºè¶‹åŠ¿",
        "å¯å†ç”Ÿèƒ½æºæŠ•èµ„å‰æ™¯"
    ]
    
    # å¹¶è¡Œåˆ›å»ºç ”ç©¶ä»»åŠ¡
    tasks = []
    for market in markets:
        task = await client.research.create(
            topic=market,
            mode="auto",
            template="business",
            provider="openai"
        )
        tasks.append(task)
    
    # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
    results = await client.research.wait_for_all(
        [task.id for task in tasks]
    )
    
    # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
    combined_report = client.research.combine_reports(
        results,
        title="å¸‚åœºåˆ†æç»¼åˆæŠ¥å‘Š"
    )
    
    return combined_report

# è¿è¡Œåˆ†æ
report = asyncio.run(analyze_markets())
print(report.content)
```

---

**é€šè¿‡ API é›†æˆï¼Œè®© DeepResearch æˆä¸ºæ‚¨åº”ç”¨çš„æ™ºèƒ½ç ”ç©¶å¼•æ“ï¼** ğŸ”Œâœ¨ 