#!/usr/bin/env python3
"""
DeepResearch - è‡ªåŠ¨åŒ–æ·±åº¦ç ”ç©¶ç³»ç»Ÿ
ä¸»ç¨‹åºå…¥å£ç‚¹ï¼Œæä¾›å‘½ä»¤è¡Œæ¥å£å’Œæ ¸å¿ƒåŠŸèƒ½è°ƒåº¦ã€‚
"""

import asyncio
import sys
from pathlib import Path
from typing import Optional
import time

import typer
from rich.console import Console
from rich.progress import Progress, SpinnerColumn, TextColumn
from rich.panel import Panel
from rich.table import Table

from config import config
from utils.logger import get_logger
from utils.markdown_export import MarkdownExporter
from utils.user_interaction import get_user_interaction
from workflow.graph import ResearchWorkflow

# Initialize components
console = Console()
logger = get_logger("main")
app = typer.Typer(
    name="deepresearch",
    help="ğŸ”¬ DeepResearch - è‡ªåŠ¨åŒ–æ·±åº¦ç ”ç©¶ç³»ç»Ÿ",
    add_completion=False
)


def display_banner():
    """Display application banner."""
    banner = """
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘                    ğŸ”¬ DeepResearch                           â•‘
    â•‘                  è‡ªåŠ¨åŒ–æ·±åº¦ç ”ç©¶ç³»ç»Ÿ                            â•‘
    â•‘                                                              â•‘
    â•‘  æ”¯æŒå¤šæ¨¡å‹LLM â€¢ æ™ºèƒ½æœç´¢ â€¢ å·¥å…·è°ƒç”¨ â€¢ ç»“æ„åŒ–æŠ¥å‘Š              â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """
    console.print(Panel(banner, style="bold blue"))


def check_system_status() -> bool:
    """
    Check system configuration and API keys.
    
    Returns:
        bool: True if system is ready, False otherwise
    """
    try:
        # Check API keys
        api_status = config.validate_api_keys()
        
        # Check if at least one LLM provider is available
        llm_available = any([
            api_status.get("openai", False),
            api_status.get("claude", False),
            api_status.get("gemini", False)
        ])
        
        if not llm_available:
            console.print("âš ï¸  è­¦å‘Š: æ²¡æœ‰å¯ç”¨çš„LLMæä¾›å•†", style="bold yellow")
            console.print("è¯·é…ç½®è‡³å°‘ä¸€ä¸ªLLM APIå¯†é’¥ (OpenAI, Claude, æˆ– Gemini)")
            return False
        
        # Check output directory
        output_dir = Path(config.system.output_dir)
        if not output_dir.exists():
            try:
                output_dir.mkdir(parents=True, exist_ok=True)
                console.print(f"ğŸ“ åˆ›å»ºè¾“å‡ºç›®å½•: {output_dir}")
            except Exception as e:
                console.print(f"âŒ æ— æ³•åˆ›å»ºè¾“å‡ºç›®å½•: {e}", style="bold red")
                return False
        
        return True
        
    except Exception as e:
        console.print(f"âŒ ç³»ç»Ÿæ£€æŸ¥å¤±è´¥: {e}", style="bold red")
        return False


async def run_research_workflow(
    topic: str,
    provider: Optional[str] = None,
    output_dir: Optional[str] = None,
    max_sections: int = 5,
    language: str = "zh-CN",
    debug: bool = False,
    streaming: bool = True,
    interactive: bool = True
) -> bool:
    """
    Run the research workflow with given parameters.
    
    Args:
        topic: Research topic
        provider: LLM provider to use
        output_dir: Output directory
        max_sections: Maximum number of sections
        language: Research language
        debug: Enable debug mode
        streaming: Enable streaming output
        interactive: Enable interactive mode
    
    Returns:
        bool: True if successful, False otherwise
    """
    if debug:
        config.development.debug_mode = True
        config.system.logging.level = "DEBUG"
    
    if not streaming:
        config.system.enable_streaming = False
    
    # Set output directory
    if output_dir:
        config.system.output_dir = output_dir
    
    # Create output directory
    output_path = Path(config.system.output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    console.print(f"\nğŸ¯ å¼€å§‹ç ”ç©¶ä¸»é¢˜: [bold cyan]{topic}[/bold cyan]")
    console.print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_path.absolute()}")
    
    if provider:
        console.print(f"ğŸ¤– ä½¿ç”¨LLM: {provider}")
    
    if interactive:
        console.print("ğŸ¤ äº¤äº’æ¨¡å¼: å¯ç”¨")
        # Get user preferences if in interactive mode
        user_interaction = get_user_interaction()
        preferences = user_interaction.get_research_preferences()
        
        # Apply preferences
        if preferences.get("research_depth") == "basic":
            max_sections = min(max_sections, 3)
        elif preferences.get("research_depth") == "comprehensive":
            max_sections = max(max_sections, 6)
        
        console.print(f"ğŸ“Š ç ”ç©¶æ·±åº¦: {preferences.get('research_depth', 'standard')}")
        console.print(f"ğŸ“š ç« èŠ‚æ•°é‡: {max_sections}")
    else:
        console.print("ğŸ¤– è‡ªåŠ¨æ¨¡å¼: æ— ç”¨æˆ·äº¤äº’")
    
    try:
        # Initialize workflow
        workflow = ResearchWorkflow(
            llm_provider=provider,
            max_sections=max_sections,
            language=language,
            interactive_mode=interactive
        )
        
        # Run research workflow
        if interactive:
            # Interactive mode - show detailed progress
            console.print("\n" + "="*60)
            console.print("ğŸš€ å¼€å§‹äº¤äº’å¼ç ”ç©¶æµç¨‹", style="bold green")
            console.print("="*60)
            
            # Step 1: Generate and confirm outline
            console.print("\nğŸ“‹ ç¬¬ä¸€æ­¥: ç”Ÿæˆç ”ç©¶æçº²")
            outline = await workflow.generate_outline(topic)
            
            if not outline:
                console.print("âŒ æçº²ç”Ÿæˆå¤±è´¥", style="bold red")
                return False
            
            # Export outline
            exporter = MarkdownExporter(config.system.output_dir)
            outline_file = exporter.export_outline(outline)
            console.print(f"ğŸ“„ æçº²å·²ä¿å­˜: {outline_file}")
            
            # Step 2: Generate content
            console.print("\nğŸ“ ç¬¬äºŒæ­¥: ç”Ÿæˆç ”ç©¶å†…å®¹")
            with Progress(
                SpinnerColumn(),
                TextColumn("[progress.description]{task.description}"),
                console=console
            ) as progress:
                task = progress.add_task("æ­£åœ¨ç”Ÿæˆå†…å®¹...", total=None)
                content_map = await workflow.generate_content(outline)
                progress.update(task, completed=True, description="âœ… å†…å®¹ç”Ÿæˆå®Œæˆ")
            
            # Step 3: Export final report
            console.print("\nğŸ“Š ç¬¬ä¸‰æ­¥: å¯¼å‡ºæœ€ç»ˆæŠ¥å‘Š")
            report_file = exporter.export_full_report(outline, content_map)
            
        else:
            # Non-interactive mode - use progress bars
            with Progress(
                SpinnerColumn(),
                TextColumn("[progress.description]{task.description}"),
                console=console
            ) as progress:
                
                # Step 1: Generate outline
                task1 = progress.add_task("ğŸ—‚ï¸  ç”Ÿæˆç ”ç©¶æçº²...", total=None)
                outline = await workflow.generate_outline(topic)
                progress.update(task1, completed=True, description="âœ… ç ”ç©¶æçº²å·²ç”Ÿæˆ")
                
                if not outline:
                    console.print("âŒ æçº²ç”Ÿæˆå¤±è´¥", style="bold red")
                    return False
                
                # Export outline
                exporter = MarkdownExporter(config.system.output_dir)
                outline_file = exporter.export_outline(outline)
                console.print(f"ğŸ“„ æçº²å·²ä¿å­˜: {outline_file}")
                
                # Step 2: Generate content
                task2 = progress.add_task("ğŸ“ ç”Ÿæˆç ”ç©¶å†…å®¹...", total=None)
                content_map = await workflow.generate_content(outline)
                progress.update(task2, completed=True, description="âœ… ç ”ç©¶å†…å®¹å·²ç”Ÿæˆ")
                
                # Step 3: Export final report
                task3 = progress.add_task("ğŸ“Š å¯¼å‡ºæœ€ç»ˆæŠ¥å‘Š...", total=None)
                report_file = exporter.export_full_report(outline, content_map)
                progress.update(task3, completed=True, description="âœ… æœ€ç»ˆæŠ¥å‘Šå·²å¯¼å‡º")
        
        # Display results
        console.print("\nğŸ‰ ç ”ç©¶å®Œæˆ!", style="bold green")
        console.print(f"ğŸ“„ æœ€ç»ˆæŠ¥å‘Š: [link]{report_file}[/link]")
        
        # Show progress summary
        progress_summary = exporter.get_progress_summary(content_map)
        console.print(f"ğŸ“Š å®Œæˆåº¦: {progress_summary['completion_rate']:.1%}")
        console.print(f"ğŸ“ ç”Ÿæˆå†…å®¹: {progress_summary['completed_items']}/{progress_summary['total_items']} ä¸ªéƒ¨åˆ†")
        
        return True
        
    except KeyboardInterrupt:
        console.print("\nâ¹ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ", style="bold yellow")
        return False
    except Exception as e:
        logger.error(f"Research failed: {e}", exc_info=True)
        console.print(f"\nâŒ ç ”ç©¶å¤±è´¥: {str(e)}", style="bold red")
        return False


@app.command()
def research(
    topic: str = typer.Argument(..., help="ç ”ç©¶ä¸»é¢˜"),
    provider: Optional[str] = typer.Option(None, "--provider", "-p", help="æŒ‡å®šLLMæä¾›å•† (openai/claude/gemini/ollama/deepseek)"),
    output_dir: Optional[str] = typer.Option(None, "--output", "-o", help="è¾“å‡ºç›®å½•"),
    max_sections: int = typer.Option(5, "--max-sections", help="æœ€å¤§ç« èŠ‚æ•°"),
    language: str = typer.Option("zh-CN", "--language", "-l", help="ç ”ç©¶è¯­è¨€"),
    debug: bool = typer.Option(False, "--debug", help="å¯ç”¨è°ƒè¯•æ¨¡å¼"),
    streaming: bool = typer.Option(True, "--streaming/--no-streaming", help="å¯ç”¨æµå¼è¾“å‡º"),
    interactive: bool = typer.Option(True, "--interactive/--auto", help="å¯ç”¨äº¤äº’æ¨¡å¼")
):
    """
    ğŸ”¬ å¼€å§‹æ·±åº¦ç ”ç©¶ä»»åŠ¡
    
    ç¤ºä¾‹:
        deepresearch research "äººå·¥æ™ºèƒ½çš„å‘å±•è¶‹åŠ¿"
        deepresearch research "åŒºå—é“¾æŠ€æœ¯" --provider claude --output ./reports
        deepresearch research "é‡å­è®¡ç®—" --auto  # è‡ªåŠ¨æ¨¡å¼ï¼Œæ— ç”¨æˆ·äº¤äº’
    """
    display_banner()
    
    # Check system status
    if not check_system_status():
        console.print("\nâŒ ç³»ç»Ÿé…ç½®ä¸å®Œæ•´ï¼Œæ— æ³•ç»§ç»­", style="bold red")
        raise typer.Exit(1)
    
    # Run research workflow
    success = asyncio.run(run_research_workflow(
        topic=topic,
        provider=provider,
        output_dir=output_dir,
        max_sections=max_sections,
        language=language,
        debug=debug,
        streaming=streaming,
        interactive=interactive
    ))
    
    if not success:
        raise typer.Exit(1)


@app.command()
def interactive(
    topic: str = typer.Argument(..., help="ç ”ç©¶ä¸»é¢˜")
):
    """
    ğŸ¤ å¯åŠ¨å®Œå…¨äº¤äº’å¼ç ”ç©¶æ¨¡å¼
    
    è¿™ä¸ªæ¨¡å¼ä¼šåœ¨æ¯ä¸ªå…³é”®æ­¥éª¤è¯¢é—®ç”¨æˆ·æ„è§ï¼Œæä¾›æœ€å¤§çš„æ§åˆ¶æƒã€‚
    """
    display_banner()
    
    # Check system status
    if not check_system_status():
        console.print("\nâŒ ç³»ç»Ÿé…ç½®ä¸å®Œæ•´ï¼Œæ— æ³•ç»§ç»­", style="bold red")
        raise typer.Exit(1)
    
    console.print("ğŸ¤ å®Œå…¨äº¤äº’å¼ç ”ç©¶æ¨¡å¼", style="bold blue")
    console.print("ç³»ç»Ÿå°†åœ¨æ¯ä¸ªå…³é”®æ­¥éª¤å¾æ±‚æ‚¨çš„æ„è§\n")
    
    # Run with full interactivity
    success = asyncio.run(run_research_workflow(
        topic=topic,
        provider=None,  # Let user choose
        output_dir=None,  # Use default
        max_sections=5,  # Will be adjusted based on user preference
        language="zh-CN",
        debug=False,
        streaming=True,
        interactive=True
    ))
    
    if not success:
        raise typer.Exit(1)


@app.command()
def auto(
    topic: str = typer.Argument(..., help="ç ”ç©¶ä¸»é¢˜"),
    provider: Optional[str] = typer.Option("openai", "--provider", "-p", help="æŒ‡å®šLLMæä¾›å•†"),
    max_sections: int = typer.Option(4, "--max-sections", help="æœ€å¤§ç« èŠ‚æ•°")
):
    """
    ğŸ¤– å¯åŠ¨è‡ªåŠ¨ç ”ç©¶æ¨¡å¼
    
    è¿™ä¸ªæ¨¡å¼ä¼šè‡ªåŠ¨å®Œæˆæ•´ä¸ªç ”ç©¶æµç¨‹ï¼Œæ— éœ€ç”¨æˆ·äº¤äº’ã€‚
    """
    display_banner()
    
    # Check system status
    if not check_system_status():
        console.print("\nâŒ ç³»ç»Ÿé…ç½®ä¸å®Œæ•´ï¼Œæ— æ³•ç»§ç»­", style="bold red")
        raise typer.Exit(1)
    
    console.print("ğŸ¤– è‡ªåŠ¨ç ”ç©¶æ¨¡å¼", style="bold blue")
    console.print("ç³»ç»Ÿå°†è‡ªåŠ¨å®Œæˆæ•´ä¸ªç ”ç©¶æµç¨‹\n")
    
    # Run without interactivity
    success = asyncio.run(run_research_workflow(
        topic=topic,
        provider=provider,
        output_dir=None,
        max_sections=max_sections,
        language="zh-CN",
        debug=False,
        streaming=True,
        interactive=False
    ))
    
    if not success:
        raise typer.Exit(1)


@app.command()
def config_check():
    """
    ğŸ”§ æ£€æŸ¥é…ç½®æ–‡ä»¶å’ŒAPIå¯†é’¥
    """
    console.print("ğŸ”§ é…ç½®æ£€æŸ¥", style="bold blue")
    
    # Check configuration
    api_status = config.validate_api_keys()
    
    console.print("\nğŸ“‹ å½“å‰é…ç½®:")
    console.print(f"  é»˜è®¤LLMæä¾›å•†: {config.llm.default_provider}")
    console.print(f"  é»˜è®¤æœç´¢å¼•æ“: {config.search.default_engine}")
    console.print(f"  è¾“å‡ºç›®å½•: {config.system.output_dir}")
    console.print(f"  æ—¥å¿—çº§åˆ«: {config.system.logging.level}")
    console.print(f"  è°ƒè¯•æ¨¡å¼: {config.development.debug_mode}")
    
    console.print("\nğŸ”‘ APIå¯†é’¥çŠ¶æ€:")
    for service, available in api_status.items():
        status = "âœ…" if available else "âŒ"
        console.print(f"  {service}: {status}")
    
    # Recommendations
    console.print("\nğŸ’¡ å»ºè®®:")
    if not api_status.get("openai") and not api_status.get("claude"):
        console.print("  - é…ç½®è‡³å°‘ä¸€ä¸ªä¸»æµLLMæä¾›å•† (OpenAI æˆ– Claude)")
    
    if not api_status.get("serpapi") and not api_status.get("bing"):
        console.print("  - é…ç½®æœç´¢APIä»¥è·å¾—æ›´å¥½çš„æœç´¢ç»“æœ (SerpAPI æˆ– Bing)")
    
    if not api_status.get("google_drive") and not api_status.get("dropbox"):
        console.print("  - é…ç½®äº‘å­˜å‚¨æœåŠ¡ä»¥æ”¯æŒæ–‡ä»¶é›†æˆåŠŸèƒ½")


@app.command()
def config_show():
    """
    ğŸ“‹ æ˜¾ç¤ºå½“å‰é…ç½®æ‘˜è¦
    """
    console.print("ğŸ“‹ é…ç½®æ‘˜è¦", style="bold blue")
    
    summary = config.get_config_summary()
    
    # Create configuration table
    table = Table(title="ç³»ç»Ÿé…ç½®")
    table.add_column("é…ç½®é¡¹", style="cyan")
    table.add_column("å½“å‰å€¼", style="green")
    
    table.add_row("LLMæä¾›å•†", summary["llm_provider"])
    table.add_row("æœç´¢å¼•æ“", summary["search_engine"])
    table.add_row("è¾“å‡ºç›®å½•", summary["output_dir"])
    table.add_row("è°ƒè¯•æ¨¡å¼", "å¯ç”¨" if summary["debug_mode"] else "ç¦ç”¨")
    
    console.print(table)
    
    # Show tools status
    console.print("\nğŸ”§ å·¥å…·çŠ¶æ€:")
    for tool, enabled in summary["tools_enabled"].items():
        status = "âœ… å¯ç”¨" if enabled else "âŒ ç¦ç”¨"
        console.print(f"  {tool}: {status}")
    
    # Show API keys status
    console.print("\nğŸ”‘ APIå¯†é’¥:")
    for service, available in summary["api_keys_available"].items():
        status = "âœ… å·²é…ç½®" if available else "âŒ æœªé…ç½®"
        console.print(f"  {service}: {status}")


@app.command()
def config_edit():
    """
    âœï¸  ç¼–è¾‘é…ç½®æ–‡ä»¶
    """
    console.print("âœï¸  é…ç½®ç¼–è¾‘", style="bold blue")
    
    config_path = Path("config.yml")
    
    if not config_path.exists():
        console.print("âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œç³»ç»Ÿç”Ÿæˆé»˜è®¤é…ç½®", style="bold red")
        return
    
    # Try to open with default editor
    import os
    import subprocess
    
    try:
        if os.name == 'nt':  # Windows
            os.startfile(str(config_path))
        elif os.name == 'posix':  # macOS and Linux
            subprocess.call(['open', str(config_path)])
        else:
            console.print(f"è¯·æ‰‹åŠ¨ç¼–è¾‘é…ç½®æ–‡ä»¶: {config_path.absolute()}")
    except Exception as e:
        console.print(f"æ— æ³•è‡ªåŠ¨æ‰“å¼€ç¼–è¾‘å™¨: {e}")
        console.print(f"è¯·æ‰‹åŠ¨ç¼–è¾‘é…ç½®æ–‡ä»¶: {config_path.absolute()}")


@app.command()
def config_reset(
    confirm: bool = typer.Option(False, "--confirm", help="ç¡®è®¤é‡ç½®é…ç½®")
):
    """
    ğŸ”„ é‡ç½®é…ç½®æ–‡ä»¶åˆ°é»˜è®¤å€¼
    """
    console.print("ğŸ”„ é‡ç½®é…ç½®", style="bold blue")
    
    if not confirm:
        console.print("âš ï¸  è¿™å°†é‡ç½®æ‰€æœ‰é…ç½®åˆ°é»˜è®¤å€¼ï¼Œæ‰€æœ‰è‡ªå®šä¹‰é…ç½®å°†ä¸¢å¤±ï¼")
        console.print("å¦‚æœç¡®è®¤è¦é‡ç½®ï¼Œè¯·ä½¿ç”¨: python main.py config-reset --confirm")
        return
    
    try:
        import shutil
        from pathlib import Path
        
        config_path = Path("config.yml")
        
        # Backup existing config
        if config_path.exists():
            backup_path = Path(f"config.yml.backup.{int(time.time())}")
            shutil.copy2(config_path, backup_path)
            console.print(f"ğŸ“ å·²å¤‡ä»½ç°æœ‰é…ç½®åˆ°: {backup_path}")
        
        # Remove existing config to trigger default creation
        if config_path.exists():
            config_path.unlink()
        
        # Reload config (will create default)
        config.reload_config()
        
        console.print("âœ… é…ç½®å·²é‡ç½®åˆ°é»˜è®¤å€¼")
        
    except Exception as e:
        console.print(f"âŒ é…ç½®é‡ç½®å¤±è´¥: {str(e)}", style="bold red")


@app.command()
def config_validate():
    """
    âœ… éªŒè¯é…ç½®æ–‡ä»¶
    """
    console.print("âœ… é…ç½®éªŒè¯", style="bold blue")
    
    try:
        # Test configuration loading
        from pathlib import Path
        import yaml
        
        config_path = Path("config.yml")
        
        if not config_path.exists():
            console.print("âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨", style="bold red")
            return
        
        # Test YAML parsing
        with open(config_path, 'r', encoding='utf-8') as f:
            config_data = yaml.safe_load(f)
        
        console.print("âœ… YAML æ ¼å¼æ­£ç¡®")
        
        # Test configuration loading
        config.reload_config()
        console.print("âœ… é…ç½®åŠ è½½æˆåŠŸ")
        
        # Validate API keys
        api_status = config.validate_api_keys()
        available_apis = sum(api_status.values())
        total_apis = len(api_status)
        
        console.print(f"ğŸ”‘ API å¯†é’¥: {available_apis}/{total_apis} å·²é…ç½®")
        
        # Check required sections
        required_sections = ['llm', 'search', 'system', 'tools']
        missing_sections = [s for s in required_sections if s not in config_data]
        
        if missing_sections:
            console.print(f"âš ï¸  ç¼ºå°‘é…ç½®èŠ‚: {', '.join(missing_sections)}", style="bold yellow")
        else:
            console.print("âœ… æ‰€æœ‰å¿…éœ€é…ç½®èŠ‚éƒ½å­˜åœ¨")
        
        console.print("âœ… é…ç½®éªŒè¯å®Œæˆ")
        
    except Exception as e:
        console.print(f"âŒ é…ç½®éªŒè¯å¤±è´¥: {str(e)}", style="bold red")


@app.command()
def demo(
    provider: Optional[str] = typer.Option("openai", "--provider", "-p", help="LLMæä¾›å•†")
):
    """
    ğŸš€ è¿è¡Œæ¼”ç¤ºç¤ºä¾‹
    """
    display_banner()
    
    # Check system status first
    if not check_system_status():
        console.print("\nâŒ ç³»ç»Ÿé…ç½®ä¸å®Œæ•´ï¼Œæ— æ³•ç»§ç»­", style="bold red")
        raise typer.Exit(1)
    
    demo_topics = [
        "äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨",
        "å¯æŒç»­èƒ½æºå‘å±•è¶‹åŠ¿",
        "åŒºå—é“¾æŠ€æœ¯çš„å•†ä¸šåº”ç”¨",
        "é‡å­è®¡ç®—çš„å‘å±•å‰æ™¯"
    ]
    
    console.print("ğŸš€ æ¼”ç¤ºæ¨¡å¼", style="bold blue")
    console.print("é€‰æ‹©ä¸€ä¸ªæ¼”ç¤ºä¸»é¢˜:")
    
    for i, topic in enumerate(demo_topics, 1):
        console.print(f"  {i}. {topic}")
    
    choice = typer.prompt("è¯·é€‰æ‹© (1-4)", type=int)
    
    if 1 <= choice <= len(demo_topics):
        selected_topic = demo_topics[choice - 1]
        console.print(f"\nğŸ¯ å¼€å§‹æ¼”ç¤ºç ”ç©¶: {selected_topic}")
        
        # Ask for mode
        mode_choice = typer.prompt("é€‰æ‹©æ¨¡å¼ (1=äº¤äº’å¼, 2=è‡ªåŠ¨)", type=int, default=1)
        interactive_mode = mode_choice == 1
        
        # Run research workflow with selected topic
        success = asyncio.run(run_research_workflow(
            topic=selected_topic,
            provider=provider,
            output_dir=None,  # Use default output directory
            max_sections=3,   # Smaller for demo
            language="zh-CN",
            debug=False,
            streaming=True,
            interactive=interactive_mode
        ))
        
        if not success:
            raise typer.Exit(1)
    else:
        console.print("âŒ æ— æ•ˆé€‰æ‹©", style="bold red")
        raise typer.Exit(1)


@app.command()
def version():
    """
    ğŸ“¦ æ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯
    """
    console.print("ğŸ“¦ ç‰ˆæœ¬ä¿¡æ¯", style="bold blue")
    console.print("DeepResearch v1.0.0")
    console.print("è‡ªåŠ¨åŒ–æ·±åº¦ç ”ç©¶ç³»ç»Ÿ")
    console.print("\nğŸ”— é¡¹ç›®åœ°å€: https://github.com/your-repo/deepresearch")
    console.print("ğŸ“§ è”ç³»æ–¹å¼: your-email@example.com")


if __name__ == "__main__":
    app() 