#!/usr/bin/env python3
"""
DeepResearch LangGraph Studio Python API
æä¾› Studio å·¥ä½œæµçš„ Python è°ƒç”¨æ¥å£
"""

import asyncio
import argparse
import sys
import os
import json
from typing import Dict, Any

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from workflow.studio_workflow import run_studio_research
from utils.logger import LoggerMixin


class StudioAPI(LoggerMixin):
    """Studio API æ¥å£"""
    
    def __init__(self):
        """åˆå§‹åŒ– API"""
        pass
    
    def show_banner(self):
        """æ˜¾ç¤ºæ¨ªå¹…"""
        print("""
ğŸ¨ DeepResearch LangGraph Studio
================================
AIé©±åŠ¨çš„å¯è§†åŒ–ç ”ç©¶å·¥ä½œæµç³»ç»Ÿ

ç‰ˆæœ¬: 1.0.0
Studio å›¾: studio_research_workflow
        """)
    
    async def run_research(
        self, 
        topic: str, 
        provider: str = "deepseek",
        depth: str = "intermediate",
        language: str = "zh-CN"
    ) -> Dict[str, Any]:
        """è¿è¡Œç ”ç©¶å·¥ä½œæµ"""
        
        print(f"ğŸš€ å¯åŠ¨ Studio ç ”ç©¶å·¥ä½œæµ...")
        print(f"ğŸ“ ä¸»é¢˜: {topic}")
        print(f"ğŸ¤– LLM: {provider}")
        print(f"ğŸ“Š æ·±åº¦: {depth}")
        print(f"ğŸŒ è¯­è¨€: {language}")
        print("-" * 50)
        
        try:
            result = await run_studio_research(
                topic=topic,
                research_depth=depth,
                language=language,
                llm_provider=provider
            )
            
            self._display_results(result)
            return result
            
        except Exception as e:
            print(f"âŒ ç ”ç©¶å¤±è´¥: {e}")
            self.log_error(f"Research failed: {e}")
            return {"stage": "error", "error_message": str(e)}
    
    def _display_results(self, result: Dict[str, Any]):
        """æ˜¾ç¤ºç ”ç©¶ç»“æœ"""
        print("\n" + "="*50)
        print("ğŸ“Š ç ”ç©¶ç»“æœ")
        print("="*50)
        
        stage = result.get("stage", "unknown")
        print(f"é˜¶æ®µ: {stage}")
        
        if stage == "complete":
            print("ğŸ‰ ç ”ç©¶æˆåŠŸå®Œæˆ!")
            
            # å¤§çº²ä¿¡æ¯
            outline = result.get("outline")
            if outline:
                print(f"\nğŸ“‹ å¤§çº²: {outline.get('title', 'N/A')}")
                sections = outline.get("sections", [])
                print(f"ğŸ“„ ç« èŠ‚æ•°: {len(sections)}")
                
                for i, section in enumerate(sections, 1):
                    print(f"  {i}. {section.get('title', 'N/A')}")
            
            # å†…å®¹ä¿¡æ¯
            content_map = result.get("content_map", {})
            if content_map:
                print(f"\nâœï¸  ç”Ÿæˆå†…å®¹: {len(content_map)} ä¸ªç« èŠ‚")
                total_length = sum(
                    len(content.get("content", "")) 
                    for content in content_map.values()
                )
                print(f"ğŸ“ æ€»å­—æ•°: {total_length:,} å­—")
            
            # æœç´¢ä¿¡æ¯
            search_results = result.get("search_results", [])
            if search_results:
                print(f"\nğŸ” æœç´¢ç»“æœ: {len(search_results)} ä¸ª")
                engines_used = set(r.get("engine") for r in search_results)
                print(f"ğŸ”§ ä½¿ç”¨å¼•æ“: {', '.join(engines_used)}")
            
            # æ€§èƒ½æŒ‡æ ‡
            performance = result.get("performance_metrics", {})
            if performance:
                total_time = performance.get("total_execution_time", 0)
                api_calls = performance.get("total_api_calls", 0)
                print(f"\nâš¡ æ€§èƒ½:")
                print(f"  â±ï¸  æ€»è€—æ—¶: {total_time:.2f}s")
                print(f"  ğŸ”„ APIè°ƒç”¨: {api_calls} æ¬¡")
        
        elif stage == "error":
            print("âŒ ç ”ç©¶å¤±è´¥")
            error_msg = result.get("error_message", "Unknown error")
            print(f"é”™è¯¯: {error_msg}")
        
        else:
            print(f"âš ï¸  ç ”ç©¶æœªå®Œæˆ (å½“å‰é˜¶æ®µ: {stage})")
        
        # æ‰§è¡Œæ—¥å¿—
        execution_log = result.get("execution_log", [])
        if execution_log:
            print(f"\nğŸ“ æ‰§è¡Œæ—¥å¿— (æœ€è¿‘ 5 æ¡):")
            for log_entry in execution_log[-5:]:
                print(f"  {log_entry}")
        
        print("\n" + "="*50)
    
    def show_studio_info(self):
        """æ˜¾ç¤º Studio ä¿¡æ¯å’Œä½¿ç”¨æŒ‡å—"""
        print("""
ğŸ¨ LangGraph Studio ä½¿ç”¨æŒ‡å—
==========================

å¿«é€Ÿå¯åŠ¨:
  ./run.sh studio-demo                    # è¿è¡Œæ¼”ç¤º
  ./run.sh studio-research "ä¸»é¢˜"          # å¯åŠ¨ç ”ç©¶
  ./run.sh studio-setup                   # è®¾ç½®ç¯å¢ƒ

å®‰è£… LangGraph Studio:
  1. è®¿é—®: https://github.com/langchain-ai/langgraph-studio/releases
  2. ä¸‹è½½ macOS ç‰ˆæœ¬å¹¶å®‰è£…

é…ç½®æ­¥éª¤:
  1. è¿è¡Œ: ./run.sh studio-setup
  2. åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® LANGCHAIN_API_KEY
  3. å¯åŠ¨ LangGraph Studio åº”ç”¨
  4. æ‰“å¼€é¡¹ç›®ç›®å½•å¹¶é€‰æ‹© 'studio_research_workflow'

å·¥ä½œæµèŠ‚ç‚¹è¯´æ˜:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸš€ initialize          - åˆå§‹åŒ–ç ”ç©¶å‚æ•°
ğŸ“‹ generate_outline     - ç”Ÿæˆç ”ç©¶å¤§çº²  
ğŸ” review_outline       - å®¡æ ¸å¤§çº²è´¨é‡
ğŸ” search_information   - æœç´¢ç›¸å…³ä¿¡æ¯
âœï¸  generate_content     - ç”Ÿæˆç ”ç©¶å†…å®¹
ğŸ“ review_content       - å®¡æ ¸å†…å®¹è´¨é‡
ğŸ“„ finalize_report      - å®Œæˆæœ€ç»ˆæŠ¥å‘Š
âŒ handle_error         - å¤„ç†å¼‚å¸¸æƒ…å†µ

å¼€å§‹æ‚¨çš„å¯è§†åŒ–ç ”ç©¶ä¹‹æ—…! ğŸš€
        """)
    
    def export_config(self, output_file: str = "studio_config.json"):
        """å¯¼å‡º Studio é…ç½®"""
        config_data = {
            "project": "DeepResearch",
            "version": "1.0.0",
            "studio_workflow": "studio_research_workflow",
            "description": "AIé©±åŠ¨çš„è‡ªåŠ¨åŒ–æ·±åº¦ç ”ç©¶ç³»ç»Ÿ",
            "features": [
                "å¯è§†åŒ–å·¥ä½œæµè°ƒè¯•",
                "å®æ—¶çŠ¶æ€ç›‘æ§",
                "äº¤äº’å¼æ–­ç‚¹è°ƒè¯•",
                "æ€§èƒ½æŒ‡æ ‡åˆ†æ",
                "å¤šLLMæä¾›å•†æ”¯æŒ",
                "å¤šæœç´¢å¼•æ“é›†æˆ"
            ],
            "supported_llm_providers": [
                "openai", "claude", "gemini", "deepseek", "ollama"
            ],
            "supported_search_engines": [
                "tavily", "duckduckgo", "arxiv", "brave", "google", "bing"
            ],
            "workflow_nodes": [
                "initialize", "generate_outline", "review_outline",
                "search_information", "generate_content", "review_content",
                "finalize_report", "handle_error"
            ]
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(config_data, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… Studio é…ç½®å·²å¯¼å‡ºåˆ°: {output_file}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="DeepResearch Studio Python API",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  python studio.py --info                        # æ˜¾ç¤ºä½¿ç”¨æŒ‡å—
  python studio.py --run "AIå‘å±•è¶‹åŠ¿"             # è¿è¡Œç ”ç©¶
  python studio.py --run "é‡å­è®¡ç®—" --provider deepseek --depth advanced

æ¨èä½¿ç”¨ run.sh ç»Ÿä¸€å…¥å£:
  ./run.sh studio-demo                          # è¿è¡Œæ¼”ç¤º
  ./run.sh studio-research "ä¸»é¢˜" --provider deepseek
        """
    )
    
    # ä¸»è¦æ“ä½œå‚æ•°
    parser.add_argument(
        "--run", 
        type=str, 
        metavar="TOPIC",
        help="è¿è¡Œç ”ç©¶å·¥ä½œæµï¼ŒæŒ‡å®šç ”ç©¶ä¸»é¢˜"
    )
    
    parser.add_argument(
        "--provider", 
        type=str, 
        default="deepseek",
        choices=["openai", "claude", "gemini", "deepseek", "ollama"],
        help="LLM æä¾›å•† (é»˜è®¤: deepseek)"
    )
    
    parser.add_argument(
        "--depth", 
        type=str, 
        default="intermediate",
        choices=["basic", "intermediate", "advanced"],
        help="ç ”ç©¶æ·±åº¦ (é»˜è®¤: intermediate)"
    )
    
    parser.add_argument(
        "--language", 
        type=str, 
        default="zh-CN",
        help="ç ”ç©¶è¯­è¨€ (é»˜è®¤: zh-CN)"
    )
    
    # ä¿¡æ¯å’Œé…ç½®å‚æ•°
    parser.add_argument(
        "--info", 
        action="store_true",
        help="æ˜¾ç¤º LangGraph Studio ä½¿ç”¨æŒ‡å—"
    )
    
    parser.add_argument(
        "--export-config", 
        type=str, 
        nargs="?",
        const="studio_config.json",
        metavar="FILE",
        help="å¯¼å‡º Studio é…ç½®åˆ°æ–‡ä»¶"
    )
    
    args = parser.parse_args()
    
    # åˆ›å»º API å®ä¾‹
    studio_api = StudioAPI()
    studio_api.show_banner()
    
    # å¤„ç†å‚æ•°
    if args.info:
        studio_api.show_studio_info()
        return
    
    if args.export_config:
        studio_api.export_config(args.export_config)
        return
    
    if args.run:
        # è¿è¡Œç ”ç©¶
        try:
            result = asyncio.run(studio_api.run_research(
                topic=args.run,
                provider=args.provider,
                depth=args.depth,
                language=args.language
            ))
            
            if result.get("stage") == "complete":
                print("\nğŸ¯ ä¸‹ä¸€æ­¥:")
                print("1. åœ¨ LangGraph Studio ä¸­æ‰“å¼€é¡¹ç›®ç›®å½•")
                print("2. é€‰æ‹© 'studio_research_workflow' å›¾")
                print("3. é‡æ–°è¿è¡Œä»¥è§‚å¯Ÿå¯è§†åŒ–è°ƒè¯•è¿‡ç¨‹")
                sys.exit(0)
            else:
                sys.exit(1)
                
        except KeyboardInterrupt:
            print("\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
            sys.exit(0)
        except Exception as e:
            print(f"\nâŒ è¿è¡Œå¤±è´¥: {e}")
            sys.exit(1)
    
    # é»˜è®¤æ˜¾ç¤ºå¸®åŠ©
    parser.print_help()


if __name__ == "__main__":
    main() 